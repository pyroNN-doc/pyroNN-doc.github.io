{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> <p>I like to play    after drinking </p>"},{"location":"PyroNN_demonstration/","title":"Demonstration of Python Reconstruction Operators in Neural Networks (Pyro-NN)","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\n</pre> %matplotlib inline In\u00a0[2]: Copied! <pre>import torch\nimport pyronn\nimport numpy as np\n</pre> import torch import pyronn import numpy as np <p>2.3. Internal Structure</p> <p>The methodology of Pyro-NN is contained within the \"ct_reconstruction\" folder. This folder is divided into four main parts:</p> <ol> <li>Geometry: Defines the scanning parameters and trajectory.<ul> <li>Initialization from parameters: Possible if you know all your scanning parameters and your scanning trajectory was a circle.</li> <li>Initialization from EZRT Header: Automatic setup of the scanning environment, since positioning is known also possible for arbitrary trajectories.</li> <li>=&gt; Small Hint: Sometimes Parameters in the Header are filled wrong by XSimulation and/or Firefly. Errors can still occure!</li> </ul> </li> <li>Layers: Contains the definitions of the 2D and 3D forward/backward projectors.<ul> <li>For initializing these layers, the geometry of the scan need to be defined.</li> <li>Input of all layers is the Image-Tensor (from the respective dimension) and a geometry dict, returned when initializing the geometry.</li> <li>For 2D: Parallel Beam and Fan Beam are implemented.</li> <li>For 3D: Cone Beam is implemented.</li> </ul> </li> <li>Helpers: Provides pre-implemented filters, weights, trajectories, and phantoms.<ul> <li>Implemented filter: Ramp Filters, Ram Lak, Shepp Logan, Cosine, Hamming, Hann</li> <li>Implemented weights: Cosine, Parker</li> <li>Implemented trajectories: circular and arbitrary</li> </ul> </li> <li>Cores: Stores the kernels and the torch connection.</li> </ol> In\u00a0[3]: Copied! <pre>from PythonTools import raw2py\nimport matplotlib.pyplot as plt\nfrom get_natsorted_images import get_images_sorted\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n# Define folder and load image natually sorted. \nprojection_folder = r\"D:\\simulated_data\\circ_diff_reco_test\\0001581_partstudio_00_model_ste_00_2048\"\nprojection_paths = get_images_sorted(projection_folder)\nimages = list()\nheaders = list()\n# Define basic transformation to get projections as tensors and with data range (0,1)\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 65535,inplace = True)]) #For Range -1,1 : (32767.5, 32767.5)\nfor i,proj in enumerate(projection_paths):\n    header, img = raw2py.raw2py(proj,switch_order=True)\n    img = Image.fromarray(img)\n    # Convert image to float before normalization\n    img = img.convert('F')       \n    images.append(transform(img).float())\n    headers.append(header)\n\n# Visualization of the images\n# Create the figure and axis object\nfig, ax = plt.subplots()\n\n# Load a single image, transform to numpy array for plotting\nimage = images[5].cpu().squeeze().detach().numpy()\n\n# Display the image\nplt.figure()\nax.imshow(image, cmap=\"gray\")\nax.axis('off')\n\n# Show the figure\nplt.show()\n</pre> from PythonTools import raw2py import matplotlib.pyplot as plt from get_natsorted_images import get_images_sorted from PIL import Image import torchvision.transforms as transforms  # Define folder and load image natually sorted.  projection_folder = r\"D:\\simulated_data\\circ_diff_reco_test\\0001581_partstudio_00_model_ste_00_2048\" projection_paths = get_images_sorted(projection_folder) images = list() headers = list() # Define basic transformation to get projections as tensors and with data range (0,1) transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0, 65535,inplace = True)]) #For Range -1,1 : (32767.5, 32767.5) for i,proj in enumerate(projection_paths):     header, img = raw2py.raw2py(proj,switch_order=True)     img = Image.fromarray(img)     # Convert image to float before normalization     img = img.convert('F')            images.append(transform(img).float())     headers.append(header)  # Visualization of the images # Create the figure and axis object fig, ax = plt.subplots()  # Load a single image, transform to numpy array for plotting image = images[5].cpu().squeeze().detach().numpy()  # Display the image plt.figure() ax.imshow(image, cmap=\"gray\") ax.axis('off')  # Show the figure plt.show()  <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <p>As a next step, we have to initialize the geometry of our scan. If we have an EZRT Header available, we can use the informations of the header.</p> In\u00a0[4]: Copied! <pre>from pyronn.ct_reconstruction.geometry.geometry import Geometry\ngeom = Geometry()\n# Volume shape in Voxel, Volume spacing in mm\ngeom.init_from_EZRT_header(projection_headers =headers,volume_shape=[300,300,300],volume_spacing=0.5)\n</pre> from pyronn.ct_reconstruction.geometry.geometry import Geometry geom = Geometry() # Volume shape in Voxel, Volume spacing in mm geom.init_from_EZRT_header(projection_headers =headers,volume_shape=[300,300,300],volume_spacing=0.5) <pre>circ\ncirc\n</pre> <p>Since we already have some projections available, let's build a sinogram. In future, the following method should be included in the Pyro-NN Package:</p> In\u00a0[5]: Copied! <pre>def build_sinogram(images):\n    n = len(images)\n    nc = 1\n    _, width, height = images[0].size()\n    transformed_images = torch.zeros((nc, n, height, width), dtype=torch.float32)\n    # 0 you get when you input 1. in a log function. The maximum value not being infinity is torch.finfo(torch.float32).eps\n    transform = transforms.Compose([ transforms.Normalize(0,5)]) #-torch.log(torch.tensor(torch.finfo(torch.float32).eps))\n    for i in range(0, n):\n        transformed_images[:, i, :, :] = transform(-torch.log(images[i].float()))\n    return transformed_images\n\nsinogram = build_sinogram(images=images).cuda()\n\nprint(\"Shape of Sinogram: \",sinogram.shape)\nprint(\"Minimum Value in Sinogram: \",sinogram.flatten().min())\nprint(\"Maximum Value in Sinogram: \",sinogram.flatten().max())\n</pre> def build_sinogram(images):     n = len(images)     nc = 1     _, width, height = images[0].size()     transformed_images = torch.zeros((nc, n, height, width), dtype=torch.float32)     # 0 you get when you input 1. in a log function. The maximum value not being infinity is torch.finfo(torch.float32).eps     transform = transforms.Compose([ transforms.Normalize(0,5)]) #-torch.log(torch.tensor(torch.finfo(torch.float32).eps))     for i in range(0, n):         transformed_images[:, i, :, :] = transform(-torch.log(images[i].float()))     return transformed_images  sinogram = build_sinogram(images=images).cuda()  print(\"Shape of Sinogram: \",sinogram.shape) print(\"Minimum Value in Sinogram: \",sinogram.flatten().min()) print(\"Maximum Value in Sinogram: \",sinogram.flatten().max()) <pre>Shape of Sinogram:  torch.Size([1, 90, 512, 512])\nMinimum Value in Sinogram:  tensor(0.0055, device='cuda:0')\nMaximum Value in Sinogram:  tensor(0.7568, device='cuda:0')\n</pre> In\u00a0[6]: Copied! <pre># Visualization of the log transformed sinogram\n# Create the figure and axis object\nfig, ax = plt.subplots()\n\n# Load a single image, transform to numpy array for plotting\nimage = sinogram[0][5].cpu().squeeze().detach().numpy()\n\n# Display the image\nplt.figure()\nax.imshow(image, cmap=\"gray\")\nax.axis('off')\n\n# Show the figure\nplt.show()\n</pre> # Visualization of the log transformed sinogram # Create the figure and axis object fig, ax = plt.subplots()  # Load a single image, transform to numpy array for plotting image = sinogram[0][5].cpu().squeeze().detach().numpy()  # Display the image plt.figure() ax.imshow(image, cmap=\"gray\") ax.axis('off')  # Show the figure plt.show() <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <p>Next, we need to initialize the reconstruction layer. For presentation purpose, we initialize all implemented layers.</p> In\u00a0[7]: Copied! <pre>from pyronn.ct_reconstruction.layers.backprojection_3d import ConeBackProjection3D\nfrom pyronn.ct_reconstruction.layers.projection_3d import ConeProjection3D\nfrom pyronn.ct_reconstruction.layers.projection_2d import FanProjection2D,ParallelProjection2D\nfrom pyronn.ct_reconstruction.layers.backprojection_2d import FanBackProjection2D,ParallelBackProjection2D\n\n# Cone Beam 3D Forward and Backward Projector\nconeForwardProjection3D = ConeProjection3D(hardware_interp=True) # Reconstruction -&gt; Sinogram\nconeBackwardProjection3D = ConeBackProjection3D(hardware_interp=True) # Sinogram -&gt; Reconstruction\n\n# Fan Beam 2D Forward and Backward Projector\nfanForwardProjection2D = FanProjection2D() # Reconstruction -&gt; Sinogram\nfanBackwardProjection2D = FanBackProjection2D() # Sinogram -&gt; Reconstruction\n\n# Parallel Beam 2D Forward and Backward Projector\nparallelForwardProjection2D = ParallelProjection2D() # Reconstruction -&gt; Sinogram\nparallelBackwardProjection2D = ParallelBackProjection2D() # Sinogram -&gt; Reconstruction\n</pre> from pyronn.ct_reconstruction.layers.backprojection_3d import ConeBackProjection3D from pyronn.ct_reconstruction.layers.projection_3d import ConeProjection3D from pyronn.ct_reconstruction.layers.projection_2d import FanProjection2D,ParallelProjection2D from pyronn.ct_reconstruction.layers.backprojection_2d import FanBackProjection2D,ParallelBackProjection2D  # Cone Beam 3D Forward and Backward Projector coneForwardProjection3D = ConeProjection3D(hardware_interp=True) # Reconstruction -&gt; Sinogram coneBackwardProjection3D = ConeBackProjection3D(hardware_interp=True) # Sinogram -&gt; Reconstruction  # Fan Beam 2D Forward and Backward Projector fanForwardProjection2D = FanProjection2D() # Reconstruction -&gt; Sinogram fanBackwardProjection2D = FanBackProjection2D() # Sinogram -&gt; Reconstruction  # Parallel Beam 2D Forward and Backward Projector parallelForwardProjection2D = ParallelProjection2D() # Reconstruction -&gt; Sinogram parallelBackwardProjection2D = ParallelBackProjection2D() # Sinogram -&gt; Reconstruction <p>With all of those initialized, we can start reconstructing our projections. Hence, we will perform a basic filtered backprojection for a circular scan.</p> In\u00a0[8]: Copied! <pre>from pyronn.ct_reconstruction.helpers.filters.filters import ramp, ramp_3D, ram_lak_3D, shepp_logan_3D\nfrom visualize_reconstruction import show_reco_views\nfrom pyronn.ct_reconstruction.helpers.phantoms import shepp_logan\n\ndef FBP_ConeBeam(sinogram,geometry):\n    reco_filter = torch.tensor(shepp_logan_3D(geometry.detector_shape,geometry.detector_spacing,geometry.number_of_projections),dtype=torch.float32).cuda()\n    # Filter Sinogram in Fourier Domain\n    x = torch.fft.fft(sinogram.cuda(),dim=-1,norm=\"ortho\")\n    x = torch.multiply(x,reco_filter)\n    x = torch.fft.ifft(x,dim=-1,norm=\"ortho\").real\n\n    # Reconstruction\n    reconstruction = coneBackwardProjection3D.forward(x.contiguous(), **geometry)\n\n    return reconstruction\n\nreconstruction = FBP_ConeBeam(sinogram,geom)\nshow_reco_views(reconstruction,geom)\n</pre> from pyronn.ct_reconstruction.helpers.filters.filters import ramp, ramp_3D, ram_lak_3D, shepp_logan_3D from visualize_reconstruction import show_reco_views from pyronn.ct_reconstruction.helpers.phantoms import shepp_logan  def FBP_ConeBeam(sinogram,geometry):     reco_filter = torch.tensor(shepp_logan_3D(geometry.detector_shape,geometry.detector_spacing,geometry.number_of_projections),dtype=torch.float32).cuda()     # Filter Sinogram in Fourier Domain     x = torch.fft.fft(sinogram.cuda(),dim=-1,norm=\"ortho\")     x = torch.multiply(x,reco_filter)     x = torch.fft.ifft(x,dim=-1,norm=\"ortho\").real      # Reconstruction     reconstruction = coneBackwardProjection3D.forward(x.contiguous(), **geometry)      return reconstruction  reconstruction = FBP_ConeBeam(sinogram,geom) show_reco_views(reconstruction,geom)  In\u00a0[9]: Copied! <pre>def Iterative_reconstruction(sinogram, geometry, num_iterations):\n    current_sino = None\n    reco = torch.nn.Parameter(torch.unsqueeze(torch.full(size = geometry.volume_shape,fill_value=0.0, dtype=torch.float32), dim=0).float(),requires_grad=False).cuda()\n    for i in range(num_iterations):\n        current_sino = coneForwardProjection3D(reco,**geometry)\n\n        #normalize current sinogram\n        min_cs, max_cs = torch.min(current_sino.flatten()), torch.max(current_sino.flatten())\n        if (max_cs - min_cs) != 0:\n            current_sino=current_sino + min_cs\n            current_sino = current_sino /(max_cs-min_cs)\n\n        # calculate difference\n        current_sino= current_sino - sinogram\n        update = torch.multiply(2/(i+1),coneBackwardProjection3D(current_sino,**geometry))\n        reco = reco -update\n\n    return reconstruction\n\nreconstruction = Iterative_reconstruction(sinogram,geom,18)\nshow_reco_views(reconstruction,geom)\n</pre> def Iterative_reconstruction(sinogram, geometry, num_iterations):     current_sino = None     reco = torch.nn.Parameter(torch.unsqueeze(torch.full(size = geometry.volume_shape,fill_value=0.0, dtype=torch.float32), dim=0).float(),requires_grad=False).cuda()     for i in range(num_iterations):         current_sino = coneForwardProjection3D(reco,**geometry)          #normalize current sinogram         min_cs, max_cs = torch.min(current_sino.flatten()), torch.max(current_sino.flatten())         if (max_cs - min_cs) != 0:             current_sino=current_sino + min_cs             current_sino = current_sino /(max_cs-min_cs)          # calculate difference         current_sino= current_sino - sinogram         update = torch.multiply(2/(i+1),coneBackwardProjection3D(current_sino,**geometry))         reco = reco -update      return reconstruction  reconstruction = Iterative_reconstruction(sinogram,geom,18) show_reco_views(reconstruction,geom)"},{"location":"PyroNN_demonstration/#demonstration-of-python-reconstruction-operators-in-neural-networks-pyro-nn","title":"Demonstration of Python Reconstruction Operators in Neural Networks (Pyro-NN)\u00b6","text":"<p>In this notebook, we will demonstrate the capabilities of Pyro-NN, a differentiable reconstruction framework. The notebook is structured into four main parts:</p> <ol> <li>Introduction to Pyro-NN: Gain a basic understanding of the theory behind Pyro-NN.</li> <li>Installation and Setup: Learn how to install and set up Pyro-NN on your machine.</li> <li>Working with Projection Data: Explore how to work with projection data to initiate a reconstruction.</li> <li>Advanced Examples: Discover more advanced examples showcasing the usage of Pyro-NN.</li> </ol>"},{"location":"PyroNN_demonstration/#1-introduction-to-pyro-nn","title":"1. Introduction to Pyro-NN\u00b6","text":"<p>1.1 Motivation</p> <ul> <li>We can make use of known operators</li> </ul> <p></p> <ul> <li>For Deep Learning, the loss function and the amount of parameters to train can be reduced</li> <li>We can have gradient flow through different domains</li> <li>Parts of the neural network get interpretable, e.g. as filter</li> </ul> <p>1.2 Basic overview</p> <p></p> <p>1.3. General Notes</p> <ul> <li>Supports Tensorflow and PyTorch</li> <li>Full GPU Integration</li> <li>Open Source</li> <li>Apache 2.0 License</li> </ul>"},{"location":"PyroNN_demonstration/#2-installation-and-setup","title":"2. Installation and Setup\u00b6","text":"<p>2.1. Installation</p> <p>Pyro-NN can be used with two of the most powerful Python libraries for machine learning, namely PyTorch and TensorFlow. In this notebook, we will focus on using Pyro-NN with PyTorch.</p> <p>The latest version of Pyro-NN can be found in the GIT Repository. To gain access, please send an email to Linda (linda-sophie.schneider@iis-extern.fraunhofer.de) or Yipeng (yipeng.sun@iis-extern.fraunhofer.de).</p> <p>To install Pyro-NN, the following requirements must be met:</p> <ul> <li>Microsoft Visual Studio (in case you want to build it yourself)</li> <li>Microsoft Visual C++ 14.0 or greater</li> <li>Installation of the Python package \"build\"</li> <li>CUDA version greater than 10.2</li> </ul> <p>Once all of these requirements are fulfilled, follow these steps:</p> <ol> <li>Clone the repository and switch to the \"torch\" branch using the command: <code>git checkout torch</code></li> <li>Run the command: <code>python -m build .</code> (on Linux: <code>python3 -m build .</code>)</li> <li>Switch to the newly created sub-directory \"dist\"</li> <li>Build the wheel using the following command: <code>pip install pyronn-(*version_number*).whl</code></li> </ol> <p>If necessary, you can modify the <code>pyproject.toml</code> file to specify a particular torch version. However, be cautious and only make changes if you are confident in what you are doing!</p> <p>2.2. Integration into your Python Script</p>"},{"location":"PyroNN_demonstration/#3-working-with-projection-data","title":"3. Working with Projection Data\u00b6","text":"<p>We will demonstrate an example of reconstructing from the EZRT Header. To begin, we load the projections with Pytorch.</p>"},{"location":"PyroNN_demonstration/#4-advanced-examples","title":"4. Advanced Examples\u00b6","text":"<p>4.1 Iterative Reconstruction</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#cone-3d-reconstruction","title":"Cone 3D Reconstruction","text":"example_cone_3d.py<pre><code># Copyright [2019] [Christopher Syben, Markus Michen]\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# TODO: better imports\nfrom pyronn.ct_reconstruction.layers.projection_3d import ConeProjectionFor3D\nfrom pyronn.ct_reconstruction.layers.backprojection_3d import ConeBackProjectionFor3D\nfrom pyronn.ct_reconstruction.geometry.geometry_base import GeometryCone3D\nfrom pyronn.ct_reconstruction.helpers.filters import filters\nfrom pyronn.ct_reconstruction.helpers.filters import weights\nfrom pyronn.ct_reconstruction.helpers.phantoms import shepp_logan\nfrom pyronn.ct_reconstruction.helpers.misc.general_utils import fft_and_ifft\nfrom pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory import circular_trajectory_3d\nfrom pyronn.ct_reconstruction.helpers.filters.filters import shepp_logan_3D\n\n\ndef example_cone_3d():\n    # ------------------ Declare Parameters ------------------\n\n    # Volume Parameters:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    volume_size = 256\n    volume_shape = [volume_size, volume_size, volume_size]\n    volume_spacing = [0.5, 0.5, 0.5]\n\n    # Detector Parameters:\n    detector_shape = [400, 600]\n    detector_spacing = [1, 1]\n\n    # Trajectory Parameters:\n    number_of_projections = 360\n    angular_range = 2 * np.pi\n\n    sdd = 1200\n    sid = 750\n\n    # create Geometry class\n    geometry = GeometryCone3D(volume_shape=volume_shape,volume_spacing=volume_spacing,\n                                detector_shape=detector_shape,detector_spacing=detector_spacing,\n                                number_of_projections=number_of_projections,angular_range=angular_range,\n                                source_isocenter_distance=sid, source_detector_distance=sdd)\n    geometry.set_trajectory(circular_trajectory_3d(geometry.number_of_projections, geometry.angular_range,\n                                                   geometry.detector_spacing, geometry.detector_origin,\n                                                   geometry.source_isocenter_distance,\n                                                   geometry.source_detector_distance,\n                                                   True))\n    # Get Phantom 3d\n    phantom = shepp_logan.shepp_logan_3d(volume_shape)\n    # Add required batch dimension\n    phantom = np.expand_dims(phantom, axis=0)\n\n    # ------------------ Call Layers ------------------\n    # The following code is the new TF2.0 experimental way to tell\n    # Tensorflow only to allocate GPU memory needed rather then allocate every GPU memory available.\n    # This is important for the use of the hardware interpolation projector, otherwise there might be not enough memory left\n    # to allocate the texture memory on the GPU\n\n    sinogram = ConeProjectionFor3D().forward(phantom, geometry)\n\n    reco_filter = shepp_logan_3D(geometry.detector_shape,geometry.detector_spacing,geometry.number_of_projections)\n    x = fft_and_ifft(sinogram, reco_filter)\n\n    reco = ConeBackProjectionFor3D().forward(x, geometry)\n\n    plt.figure()\n    plt.imshow(np.squeeze(reco)[volume_shape[0]//2], cmap=plt.get_cmap('gist_gray'))\n    plt.axis('off')\n    plt.savefig(f'3d_cone_reco.png', dpi=150, transparent=False, bbox_inches='tight')\n\n\nif __name__ == '__main__':\n    example_cone_3d()\n</code></pre>"},{"location":"examples/#fan-2d-reconstruction","title":"Fan 2D Reconstruction","text":"example_fan_2d.py<pre><code># Copyright [2019] [Christopher Syben, Markus Michen]\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# TODO: better imports\nfrom pyronn.ct_reconstruction.layers.projection_2d import FanProjectionFor2D\nfrom pyronn.ct_reconstruction.layers.backprojection_2d import FanBackProjectionFor2D\nfrom pyronn.ct_reconstruction.geometry.geometry_base import GeometryFan2D\nfrom pyronn.ct_reconstruction.helpers.filters import filters\nfrom pyronn.ct_reconstruction.helpers.filters import weights\nfrom pyronn.ct_reconstruction.helpers.phantoms import shepp_logan\nfrom pyronn.ct_reconstruction.helpers.misc.general_utils import fft_and_ifft\nfrom pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory import circular_trajectory_2d\n\n\ndef example_fan_2d():\n    # ------------------ Declare Parameters ------------------\n\n    # Volume Parameters:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    volume_size = 512\n    volume_shape = [volume_size, volume_size]\n    volume_spacing = [0.23655,0.23655]\n\n    # Detector Parameters:\n    detector_shape = [512]\n    detector_spacing = [0.8, 0.8]\n\n    # Trajectory Parameters:\n    number_of_projections = 512\n    angular_range = 2*np.pi\n\n    sdd = 200\n    sid = 100\n\n    # create Geometry class\n    geometry = GeometryFan2D(volume_shape, volume_spacing,\n                             detector_shape, detector_spacing,\n                             number_of_projections, angular_range,\n                             sdd, sid)\n    geometry.set_trajectory(circular_trajectory_2d(geometry.number_of_projections, geometry.angular_range, True))\n\n    # Get Phantom\n    phantom = shepp_logan.shepp_logan_enhanced(volume_shape)\n    # Add required batch dimension\n    phantom = np.expand_dims(phantom,axis=0)\n    # ------------------ Call Layers ------------------\n\n    sinogram = FanProjectionFor2D().forward(phantom, geometry)\n\n    #TODO: Add Cosine weighting\n\n    redundancy_weights = weights.parker_weights_2d(geometry)\n    sinogram_redun_weighted = sinogram * redundancy_weights\n    reco_filter = filters.ram_lak_2D(detector_shape, detector_spacing, number_of_projections)\n    x = fft_and_ifft(sinogram, reco_filter)\n\n    reco = FanBackProjectionFor2D().forward(x, geometry)\n\n    plt.figure()\n    plt.imshow(np.squeeze(reco), cmap=plt.get_cmap('gist_gray'))\n    plt.axis('off')\n    plt.savefig(f'2d_fan_reco.png', dpi=150, transparent=False, bbox_inches='tight')\n\n\nif __name__ == '__main__':\n    example_fan_2d()\n</code></pre>"},{"location":"examples/#parallel-2d-reconstruction","title":"Parallel 2D Reconstruction","text":"example_parallel_2d.py<pre><code># Copyright [2019] [Christopher Syben, Markus Michen]\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport numpy as np\n\nfrom pyronn.ct_reconstruction.layers.projection_2d import ParallelProjectionFor2D\nfrom pyronn.ct_reconstruction.layers.backprojection_2d import ParallelBackProjectionFor2D\nfrom pyronn.ct_reconstruction.geometry.geometry_base import GeometryParallel2D\nfrom pyronn.ct_reconstruction.helpers.filters import filters\nfrom pyronn.ct_reconstruction.helpers.phantoms import shepp_logan\nfrom pyronn.ct_reconstruction.helpers.misc.general_utils import fft_and_ifft\nfrom pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory import circular_trajectory_2d\nimport matplotlib.pyplot as plt\n\ndef example_parallel_2d():\n    # ------------------ Declare Parameters ------------------\n\n    # Volume Parameters:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    volume_size = 256\n    volume_shape = [volume_size, volume_size]\n    volume_spacing = [1, 1]\n\n    # Detector Parameters:\n    detector_shape = [800]\n    detector_spacing = [1]\n\n    # Trajectory Parameters:\n    number_of_projections = 360\n    angular_range = 2* np.pi\n\n    # create Geometry class\n    geometry = GeometryParallel2D(volume_shape, volume_spacing, detector_shape, detector_spacing, number_of_projections, angular_range)\n    geometry.set_trajectory(circular_trajectory_2d(geometry.number_of_projections, geometry.angular_range, True))\n\n    # Get Phantom\n    phantom = shepp_logan.shepp_logan_enhanced(volume_shape)\n    # Add required batch dimension\n    phantom = np.expand_dims(phantom, axis=0)\n\n    # ------------------ Call Layers ------------------\n    sinogram = ParallelProjectionFor2D().forward(phantom, geometry)\n\n    #sinogram = sinogram + np.random.normal(\n    #    loc=np.mean(np.abs(sinogram)), scale=np.std(sinogram), size=sinogram.shape) * 0.02\n\n    reco_filter = filters.shepp_logan_2D(geometry.detector_shape, geometry.detector_spacing, geometry.number_of_projections)\n\n    # # one for all\n    # x = fft_and_ifft(sinogram, reco_filter)\n\n    # You can also do it step by step\n    import torch\n    x = torch.fft.fft(torch.tensor(sinogram).cuda(), dim=-1, norm='ortho')\n    x = torch.multiply(x, torch.tensor(reco_filter).cuda())\n    x = torch.fft.ifft(x, dim=-1, norm='ortho').real\n\n    reco = ParallelBackProjectionFor2D().forward(x, geometry)\n\n    plt.figure()\n    plt.imshow(np.squeeze(reco), cmap=plt.get_cmap('gist_gray'))\n    plt.axis('off')\n    plt.savefig(f'2d_par_reco.png', dpi=150, transparent=False, bbox_inches='tight')\n\n\nif __name__ == '__main__':\n    example_parallel_2d()\n</code></pre>"},{"location":"reference/__init__/","title":"Reference for <code>pyronn/__init__.py</code>","text":""},{"location":"reference/__init__/#pyronn.default_config","title":"pyronn.default_config","text":"<pre><code>default_config()\n</code></pre> Source code in <code>pyronn/__init__.py</code> <pre><code>def default_config():\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    config = {'backend': 'torch'}\n    with open(CONFIG_FILE, 'w') as f:\n        json.dump(config, f)\n</code></pre>"},{"location":"reference/__init__/#pyronn.read_backend","title":"pyronn.read_backend","text":"<pre><code>read_backend()\n</code></pre> Source code in <code>pyronn/__init__.py</code> <pre><code>def read_backend():\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    if not os.path.exists(CONFIG_FILE):\n        default_config()\n    with open(CONFIG_FILE, 'r') as f:\n        config = json.load(f)\n    return config['backend']\n</code></pre>"},{"location":"reference/__init__/#pyronn.set_backend","title":"pyronn.set_backend","text":"<pre><code>set_backend(value)\n</code></pre> Source code in <code>pyronn/__init__.py</code> <pre><code>def set_backend(value):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    config = {'backend': value}\n    with open(CONFIG_FILE, 'w') as f:\n        json.dump(config, f)\n</code></pre>"},{"location":"reference/ct_reconstruction/__init__/","title":"Reference for <code>pyronn/ct_reconstruction/__init__.py</code>","text":""},{"location":"reference/ct_reconstruction/__init__/#pyronn.ct_reconstruction.default_config","title":"pyronn.ct_reconstruction.default_config","text":"<pre><code>default_config()\n</code></pre> Source code in <code>pyronn/ct_reconstruction/__init__.py</code> <pre><code>def default_config():\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    config = {'backend': 'torch'}\n    with open(CONFIG_FILE, 'w') as f:\n        json.dump(config, f)\n</code></pre>"},{"location":"reference/ct_reconstruction/__init__/#pyronn.ct_reconstruction.read_backend","title":"pyronn.ct_reconstruction.read_backend","text":"<pre><code>read_backend()\n</code></pre> Source code in <code>pyronn/ct_reconstruction/__init__.py</code> <pre><code>def read_backend():\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    if not os.path.exists(CONFIG_FILE):\n        default_config()\n    with open(CONFIG_FILE, 'r') as f:\n        config = json.load(f)\n    return config['backend']\n</code></pre>"},{"location":"reference/ct_reconstruction/__init__/#pyronn.ct_reconstruction.set_backend","title":"pyronn.ct_reconstruction.set_backend","text":"<pre><code>set_backend(value)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/__init__.py</code> <pre><code>def set_backend(value):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    config = {'backend': value}\n    with open(CONFIG_FILE, 'w') as f:\n        json.dump(config, f)\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_base/","title":"Reference for <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code>","text":""},{"location":"reference/ct_reconstruction/geometry/geometry_base/#pyronn.ct_reconstruction.geometry.geometry_base.GeometryBase","title":"pyronn.ct_reconstruction.geometry.geometry_base.GeometryBase","text":"<pre><code>GeometryBase(volume_shape, volume_spacing, detector_shape, detector_spacing, number_of_projections, angular_range, source_detector_distance, source_isocenter_distance, *args, **kwargs)\n</code></pre> <p>The Base Class for the different Geometry classes. Provides commonly used members.</p> <pre><code>volume_shape:               The volume size in Z, Y, X order.\nvolume_spacing:             The spacing between voxels in Z, Y, X order.\ndetector_shape:             Shape of the detector in Y, X order.\ndetector_spacing:           The spacing between detector voxels in Y, X order.\nnumber_of_projections:      Number of equidistant projections.\nangular_range:              The covered angular range.\nsource_detector_distance:   The source to detector distance (sdd).\nsource_isocenter_distance:  The source to isocenter distance (sid).\n</code></pre> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code> <pre><code>def __init__(self,\n             volume_shape,\n             volume_spacing,\n             detector_shape,\n             detector_spacing,\n             number_of_projections,\n             angular_range,\n             source_detector_distance,\n             source_isocenter_distance,\n             *args, **kwargs):\n    \"\"\"\n        Constructor of Base Geometry Class, should only get called by sub classes.\n    Args:\n        volume_shape:               The volume size in Z, Y, X order.\n        volume_spacing:             The spacing between voxels in Z, Y, X order.\n        detector_shape:             Shape of the detector in Y, X order.\n        detector_spacing:           The spacing between detector voxels in Y, X order.\n        number_of_projections:      Number of equidistant projections.\n        angular_range:              The covered angular range.\n        source_detector_distance:   The source to detector distance (sdd).\n        source_isocenter_distance:  The source to isocenter distance (sid).\n    \"\"\"\n    self.np_dtype = np.float32  # datatype for np.arrays make sure everything will be float32\n    # self.gpu_device = True\n    # Volume Parameters:\n    self.volume_shape = np.array(volume_shape)\n    self.volume_spacing = np.array(volume_spacing, dtype=self.np_dtype)\n    self.volume_origin = -(self.volume_shape - 1) / 2.0 * self.volume_spacing\n\n    # Detector Parameters:\n    self.detector_shape = np.array(detector_shape)\n    self.detector_spacing = np.array(detector_spacing, dtype=self.np_dtype)\n    self.detector_origin = -(self.detector_shape - 1) / 2.0 * self.detector_spacing\n\n    # Trajectory Parameters:\n    self.number_of_projections = number_of_projections\n    if isinstance(angular_range, list):\n        self.angular_range = angular_range\n    else:\n        self.angular_range = [0, angular_range]\n\n    self.sinogram_shape = np.array([self.number_of_projections, *self.detector_shape])\n\n    self.source_detector_distance = source_detector_distance\n    self.source_isocenter_distance = source_isocenter_distance\n    self.fan_angle = None\n    self.cone_angle = None\n    self.projection_multiplier = None\n    self.step_size = None\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_base/#pyronn.ct_reconstruction.geometry.geometry_base.GeometryBase.get_dict","title":"get_dict","text":"<pre><code>get_dict()\n</code></pre> <p>Get the geometry as a dict.</p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code> <pre><code>def get_dict(self):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n        Get the geometry as a dict.\n    '''\n    info = {}\n    for i in dir(self):\n        if i[:2] != '__': info[i] = getattr(self, i)\n    return info\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_base/#pyronn.ct_reconstruction.geometry.geometry_base.GeometryBase.set_trajectory","title":"set_trajectory","text":"<pre><code>set_trajectory(trajectory)\n</code></pre> <pre><code>Sets the member trajectory.\n</code></pre> <p>Args:     trajectory: np.array defining the trajectory.</p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code> <pre><code>def set_trajectory(self, trajectory):\n    \"\"\"\n        Sets the member trajectory.\n    Args:\n        trajectory: np.array defining the trajectory.\n    \"\"\"\n    self.trajectory = np.array(trajectory, self.np_dtype)\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_base/#pyronn.ct_reconstruction.geometry.geometry_base.GeometryBase.update","title":"update","text":"<pre><code>update(dict)\n</code></pre> <pre><code>Change the geometry.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>new geometry values. Choose your target properties by setting them as the keys.</p> required Source code in <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code> <pre><code>def update(self, dict):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n        Change the geometry.\n\n    args:\n        dict: new geometry values. Choose your target properties by setting them as the keys.\n    '''\n    changed = []\n    for key in dict:\n        if key in dir(self):\n            setattr(self, key, dict[key])\n            self.key = dict[key]\n            changed.append(key)\n        else:\n            print(f'{key} is not a property of geometry! Please check it!')\n    if changed:\n        print(f'The following properties has been changed: {changed}')\n        if 'trajectory' not in changed:\n            print(f'Please confirm whether you need to modify the trajectory.')\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_base/#pyronn.ct_reconstruction.geometry.geometry_base.GeometryParallel2D","title":"pyronn.ct_reconstruction.geometry.geometry_base.GeometryParallel2D","text":"<pre><code>GeometryParallel2D(volume_shape, volume_spacing, detector_shape, detector_spacing, number_of_projections, angular_range, *args, **kwargs)\n</code></pre> <p>               Bases: <code>GeometryBase</code></p> <p>2D Parallel specialization of Geometry.</p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code> <pre><code>def __init__(self,\n             volume_shape, volume_spacing,\n             detector_shape, detector_spacing,\n             number_of_projections, angular_range, *args, **kwargs):\n    # init base selfmetry class with 2 dimensional members:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super().__init__(volume_shape, volume_spacing,\n                     detector_shape, detector_spacing,\n                     number_of_projections, angular_range,\n                     None, None, *args, **kwargs)\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_base/#pyronn.ct_reconstruction.geometry.geometry_base.GeometryFan2D","title":"pyronn.ct_reconstruction.geometry.geometry_base.GeometryFan2D","text":"<pre><code>GeometryFan2D(volume_shape, volume_spacing, detector_shape, detector_spacing, number_of_projections, angular_range, source_detector_distance, source_isocenter_distance, *args, **kwargs)\n</code></pre> <p>               Bases: <code>GeometryBase</code></p> <p>2D Fan specialization of Geometry.</p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code> <pre><code>def __init__(self,\n             volume_shape, volume_spacing,\n             detector_shape, detector_spacing,\n             number_of_projections, angular_range,\n             source_detector_distance, source_isocenter_distance, *args, **kwargs):\n    # init base Geometry class with 2 dimensional members:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super().__init__(volume_shape, volume_spacing,\n                     detector_shape, detector_spacing,\n                     number_of_projections, angular_range,\n                     source_detector_distance, source_isocenter_distance, *args, **kwargs)\n\n    # defined by geometry so calculate for convenience use\n    self.fan_angle = np.arctan(((self.detector_shape[0] - 1) / 2.0 * self.detector_spacing[0]) / self.source_detector_distance)\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_base/#pyronn.ct_reconstruction.geometry.geometry_base.GeometryCone3D","title":"pyronn.ct_reconstruction.geometry.geometry_base.GeometryCone3D","text":"<pre><code>GeometryCone3D(volume_shape, volume_spacing, detector_shape, detector_spacing, number_of_projections, angular_range, source_detector_distance, source_isocenter_distance, *args, **kwargs)\n</code></pre> <p>               Bases: <code>GeometryBase</code></p> <p>3D Cone specialization of Geometry.</p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_base.py</code> <pre><code>def __init__(self,\n             volume_shape, volume_spacing,\n             detector_shape, detector_spacing,\n             number_of_projections, angular_range,\n             source_detector_distance, source_isocenter_distance, *args, **kwargs):\n    # init base Geometry class with 3 dimensional members:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super().__init__(volume_shape, volume_spacing,\n                     detector_shape, detector_spacing,\n                     number_of_projections, angular_range,\n                     source_detector_distance, source_isocenter_distance, *args, **kwargs)\n\n    # defined by geometry so calculate for convenience use\n    self.fan_angle = np.arctan(((self.detector_shape[1] - 1) / 2.0 * self.detector_spacing[1]) / self.source_detector_distance)\n    self.cone_angle = np.arctan(((self.detector_shape[0] - 1) / 2.0 * self.detector_spacing[0]) / self.source_detector_distance)\n\n    # Containing the constant part of the distance weight and discretization invariant\n    self.projection_multiplier = self.source_isocenter_distance * self.source_detector_distance * detector_spacing[-1] * np.pi / self.number_of_projections\n    # TODO: need to be changed or not?\n    self.step_size = 0.2\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_specific/","title":"Reference for <code>pyronn/ct_reconstruction/geometry/geometry_specific.py</code>","text":""},{"location":"reference/ct_reconstruction/geometry/geometry_specific/#pyronn.ct_reconstruction.geometry.geometry_specific.SpecificGeometry","title":"pyronn.ct_reconstruction.geometry.geometry_specific.SpecificGeometry","text":"<pre><code>SpecificGeometry(geo_info_dict, traj_func)\n</code></pre> <p>               Bases: <code>ABC</code></p> <pre><code>geo_info_dict: All required information for creating a geometry.\n</code></pre> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_specific.py</code> <pre><code>def __init__(self, geo_info_dict, traj_func):\n    \"\"\"\n    Generate a specific geometry\n    Args:\n        geo_info_dict: All required information for creating a geometry.\n    \"\"\"\n    self.geometry_info = geo_info_dict\n    self.geometry = self.set_geo()\n    temp_info = {**geo_info_dict, **self.geometry.get_dict()}\n    self.trajectory = traj_func(**temp_info)\n    self.geometry.set_trajectory(self.trajectory)\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_specific/#pyronn.ct_reconstruction.geometry.geometry_specific.SpecificGeometry.generate_specific_phantom","title":"generate_specific_phantom","text":"<pre><code>generate_specific_phantom(phantom_func, *args, **kwargs)\n</code></pre> <p>Generates a phantom created by the given function and its corresponding sinogram.</p> <p>The method first creates a phantom based on the volume shape specified in the geometry attribute of the class. It then computes the sinogram by applying a forward projection. The projection is calculated based on the parameters defined in the geometry attribute, including the detector shape, spacing, and the source-detector configuration.</p> <p>Returns:</p> Type Description <p>Tuple[np.array, np.array]: A tuple containing two numpy arrays. The first array is the generated</p> <p>3D mask of the phantom, and the second array is the corresponding 3D sinogram obtained through</p> <p>the cone beam forward projection.</p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_specific.py</code> <pre><code>def generate_specific_phantom(self, phantom_func, *args, **kwargs):\n    \"\"\"\n    Generates a phantom created by the given function and its corresponding sinogram.\n\n    The method first creates a phantom based on the volume shape specified in the\n    geometry attribute of the class. It then computes the sinogram by applying a forward projection.\n    The projection is calculated based on the parameters defined in the\n    geometry attribute, including the detector shape, spacing, and the source-detector configuration.\n\n    Returns:\n        Tuple[np.array, np.array]: A tuple containing two numpy arrays. The first array is the generated\n        3D mask of the phantom, and the second array is the corresponding 3D sinogram obtained through\n        the cone beam forward projection.\n    \"\"\"\n    phantom = phantom_func(self.geometry_info['volume_shape'], *args, **kwargs)\n    phantom = np.expand_dims(phantom, axis=0)\n    mask = (phantom != 0)\n    sinogram = self.create_sinogram(phantom)\n    return mask, sinogram, phantom, self.geometry\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_specific/#pyronn.ct_reconstruction.geometry.geometry_specific.CircularGeometrys3D","title":"pyronn.ct_reconstruction.geometry.geometry_specific.CircularGeometrys3D","text":"<pre><code>CircularGeometrys3D(geo_dict_info)\n</code></pre> <p>               Bases: <code>SpecificGeometry</code></p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_specific.py</code> <pre><code>def __init__(self, geo_dict_info):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super().__init__(geo_dict_info, circular_trajectory_3d)\n</code></pre>"},{"location":"reference/ct_reconstruction/geometry/geometry_specific/#pyronn.ct_reconstruction.geometry.geometry_specific.ArbitraryGeometrys3D","title":"pyronn.ct_reconstruction.geometry.geometry_specific.ArbitraryGeometrys3D","text":"<pre><code>ArbitraryGeometrys3D(geo_dict_info)\n</code></pre> <p>               Bases: <code>SpecificGeometry</code></p> Source code in <code>pyronn/ct_reconstruction/geometry/geometry_specific.py</code> <pre><code>def __init__(self, geo_dict_info):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super().__init__(geo_dict_info, arbitrary_projection_matrix)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.ramp","title":"pyronn.ct_reconstruction.helpers.filters.filters.ramp","text":"<pre><code>ramp(detector_width: int) -&gt; np.array\n</code></pre> <p>create a 1d ramp filter.</p> <p>:param detector_width: width of detector(filter) :return: filter</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def ramp(detector_width:int)-&gt;np.array:\n    \"\"\"\n    create a 1d ramp filter.\n\n    :param detector_width: width of detector(filter)\n    :return: filter\n    \"\"\"\n    filter_array = np.zeros(detector_width)\n    frequency_spacing = 0.5 / (detector_width / 2.0)\n    for i in range(0, filter_array.shape[0]):\n        if i &lt;= filter_array.shape[0] / 2.0:\n            filter_array[i] = i * frequency_spacing\n        elif i &gt; filter_array.shape[0] / 2.0:\n            filter_array[i] = 0.5 - (((i - filter_array.shape[0] / 2.0)) * frequency_spacing)\n    return filter_array.astype(np.float32)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.ramp_2D","title":"pyronn.ct_reconstruction.helpers.filters.filters.ramp_2D","text":"<pre><code>ramp_2D(detector_shape: Tuple[int, int], number_of_projections: int) -&gt; np.array\n</code></pre> <p>create a 2d ramp filter.</p> <p>:param detector_shape: shape of detector :param number_of_projections: number of projections :return: a 2d ramp filter</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def ramp_2D(detector_shape:Tuple[int,int], number_of_projections:int)-&gt;np.array:\n    \"\"\"\n    create a 2d ramp filter.\n\n    :param detector_shape: shape of detector\n    :param number_of_projections: number of projections\n    :return: a 2d ramp filter\n    \"\"\"\n    detector_width = detector_shape[-1]\n\n    filter = [\n        np.reshape(\n            ramp(detector_width),\n            (1, detector_width)\n        )\n        for i in range(0, number_of_projections)\n    ]\n\n    filter = np.concatenate(filter)\n\n    return filter\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.ramp_3D","title":"pyronn.ct_reconstruction.helpers.filters.filters.ramp_3D","text":"<pre><code>ramp_3D(detector_shape: Tuple[int, int, int], number_of_projections: int) -&gt; np.array\n</code></pre> <p>create a 3d ramp filter</p> <p>:param detector_shape: shape of detector :param number_of_projections: number of projections :return: a 3d ramp filter</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def ramp_3D(detector_shape:Tuple[int,int,int], number_of_projections:int)-&gt;np.array:\n    \"\"\"\n    create a 3d ramp filter\n\n    :param detector_shape: shape of detector\n    :param number_of_projections: number of projections\n    :return: a 3d ramp filter\n    \"\"\"\n    detector_width = detector_shape[-1]\n\n    filter = [\n        np.reshape(\n            ramp(detector_width),\n            (1, 1, detector_width)\n        )\n        for i in range(0, number_of_projections)\n    ]\n\n    filter = np.concatenate(filter)\n\n    return filter\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.ram_lak","title":"pyronn.ct_reconstruction.helpers.filters.filters.ram_lak","text":"<pre><code>ram_lak(num_detectors: int, detector_spacing: float) -&gt; np.array\n</code></pre> <p>Generate the RAM-LAK (Ramp) filter in the frequency domain.</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def ram_lak(num_detectors: int, detector_spacing: float) -&gt; np.array:\n    \"\"\"Generate the RAM-LAK (Ramp) filter in the frequency domain.\"\"\"\n    frequencies = np.fft.fftfreq(num_detectors)\n    ramp = 1.0 / (detector_spacing * detector_spacing)\n    filter = ramp * np.abs(frequencies)\n\n    return filter.astype(np.float32)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.ram_lak_2D","title":"pyronn.ct_reconstruction.helpers.filters.filters.ram_lak_2D","text":"<pre><code>ram_lak_2D(detector_shape: Tuple[int, int], detector_spacing: Tuple[float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def ram_lak_2D(\n    detector_shape: Tuple[int, int],\n    detector_spacing: Tuple[float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = ram_lak(detector_width, detector_spacing_width)\n    filter_2D = np.tile(filter_1D, (number_of_projections, 1))\n\n    return filter_2D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.ram_lak_3D","title":"pyronn.ct_reconstruction.helpers.filters.filters.ram_lak_3D","text":"<pre><code>ram_lak_3D(detector_shape: Tuple[int, int, int], detector_spacing: Tuple[float, float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def ram_lak_3D(\n    detector_shape: Tuple[int, int, int],\n    detector_spacing: Tuple[float, float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = ram_lak(detector_width, detector_spacing_width)\n    filter_3D = np.tile(\n        filter_1D.reshape(1, 1, detector_width), (number_of_projections, 1, 1)\n    )\n\n    return filter_3D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.shepp_logan","title":"pyronn.ct_reconstruction.helpers.filters.filters.shepp_logan","text":"<pre><code>shepp_logan(num_detectors: int, detector_spacing: float) -&gt; np.array\n</code></pre> <p>Generate the Shepp-Logan filter in the frequency domain.</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def shepp_logan(num_detectors: int, detector_spacing: float) -&gt; np.array:\n    \"\"\"Generate the Shepp-Logan filter in the frequency domain.\"\"\"\n    frequencies = np.fft.fftfreq(num_detectors)\n    ramp = 1.0 / (detector_spacing * detector_spacing)\n    filter = ramp * np.abs(frequencies)\n    sinc_filter = np.where(\n        frequencies == 0, 1.0, np.sin(np.pi * frequencies) / (np.pi * frequencies)\n    )\n\n    return (filter * sinc_filter).astype(np.float32)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.shepp_logan_2D","title":"pyronn.ct_reconstruction.helpers.filters.filters.shepp_logan_2D","text":"<pre><code>shepp_logan_2D(detector_shape: Tuple[int, int], detector_spacing: Tuple[float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def shepp_logan_2D(\n    detector_shape: Tuple[int, int],\n    detector_spacing: Tuple[float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = shepp_logan(detector_width, detector_spacing_width)\n    filter_2D = np.tile(filter_1D, (number_of_projections, 1))\n\n    return filter_2D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.shepp_logan_3D","title":"pyronn.ct_reconstruction.helpers.filters.filters.shepp_logan_3D","text":"<pre><code>shepp_logan_3D(detector_shape: Tuple[int, int, int], detector_spacing: Tuple[float, float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def shepp_logan_3D(\n    detector_shape: Tuple[int, int, int],\n    detector_spacing: Tuple[float, float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = shepp_logan(detector_width, detector_spacing_width)\n    filter_3D = np.tile(\n        filter_1D.reshape(1, 1, detector_width), (number_of_projections, 1, 1)\n    )\n\n    return filter_3D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.cosine","title":"pyronn.ct_reconstruction.helpers.filters.filters.cosine","text":"<pre><code>cosine(num_detectors: int, detector_spacing: float) -&gt; np.array\n</code></pre> <p>Generate the Cosine filter in the frequency domain.</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def cosine(num_detectors: int, detector_spacing: float) -&gt; np.array:\n    \"\"\"Generate the Cosine filter in the frequency domain.\"\"\"\n    frequencies = np.fft.fftfreq(num_detectors)\n    ramp = 1.0 / (detector_spacing * detector_spacing)\n    filter = ramp * np.abs(frequencies) * np.cos(np.pi * frequencies / 2)\n\n    return filter.astype(np.float32)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.cosine_2D","title":"pyronn.ct_reconstruction.helpers.filters.filters.cosine_2D","text":"<pre><code>cosine_2D(detector_shape: Tuple[int, int], detector_spacing: Tuple[float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def cosine_2D(\n    detector_shape: Tuple[int, int],\n    detector_spacing: Tuple[float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = cosine(detector_width, detector_spacing_width)\n    filter_2D = np.tile(filter_1D, (number_of_projections, 1))\n\n    return filter_2D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.cosine_3D","title":"pyronn.ct_reconstruction.helpers.filters.filters.cosine_3D","text":"<pre><code>cosine_3D(detector_shape: Tuple[int, int, int], detector_spacing: Tuple[float, float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def cosine_3D(\n    detector_shape: Tuple[int, int, int],\n    detector_spacing: Tuple[float, float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = cosine(detector_width, detector_spacing_width)\n    filter_3D = np.tile(\n        filter_1D.reshape(1, 1, detector_width), (number_of_projections, 1, 1)\n    )\n\n    return filter_3D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.hamming","title":"pyronn.ct_reconstruction.helpers.filters.filters.hamming","text":"<pre><code>hamming(num_detectors: int, detector_spacing: float) -&gt; np.array\n</code></pre> <p>Generate the Hamming filter in the frequency domain.</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def hamming(num_detectors: int, detector_spacing: float) -&gt; np.array:\n    \"\"\"Generate the Hamming filter in the frequency domain.\"\"\"\n    frequencies = np.fft.fftfreq(num_detectors)\n    ramp = 1.0 / (detector_spacing * detector_spacing)\n    filter = ramp * np.abs(frequencies) * (0.54 + 0.46 * np.cos(np.pi * frequencies))\n\n    return filter.astype(np.float32)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.hamming_2D","title":"pyronn.ct_reconstruction.helpers.filters.filters.hamming_2D","text":"<pre><code>hamming_2D(detector_shape: Tuple[int, int], detector_spacing: Tuple[float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def hamming_2D(\n    detector_shape: Tuple[int, int],\n    detector_spacing: Tuple[float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = hamming(detector_width, detector_spacing_width)\n    filter_2D = np.tile(filter_1D, (number_of_projections, 1))\n\n    return filter_2D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.hamming_3D","title":"pyronn.ct_reconstruction.helpers.filters.filters.hamming_3D","text":"<pre><code>hamming_3D(detector_shape: Tuple[int, int, int], detector_spacing: Tuple[float, float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def hamming_3D(\n    detector_shape: Tuple[int, int, int],\n    detector_spacing: Tuple[float, float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = hamming(detector_width, detector_spacing_width)\n    filter_3D = np.tile(\n        filter_1D.reshape(1, 1, detector_width), (number_of_projections, 1, 1)\n    )\n\n    return filter_3D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.hann","title":"pyronn.ct_reconstruction.helpers.filters.filters.hann","text":"<pre><code>hann(num_detectors: int, detector_spacing: float) -&gt; np.array\n</code></pre> <p>Generate the Hann filter in the frequency domain.</p> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def hann(num_detectors: int, detector_spacing: float) -&gt; np.array:\n    \"\"\"Generate the Hann filter in the frequency domain.\"\"\"\n    frequencies = np.fft.fftfreq(num_detectors)\n    ramp = 1.0 / (detector_spacing * detector_spacing)\n    filter = ramp * np.abs(frequencies) * (0.5 + 0.5 * np.cos(np.pi * frequencies))\n\n    return filter.astype(np.float32)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.hann_2D","title":"pyronn.ct_reconstruction.helpers.filters.filters.hann_2D","text":"<pre><code>hann_2D(detector_shape: Tuple[int, int], detector_spacing: Tuple[float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def hann_2D(\n    detector_shape: Tuple[int, int],\n    detector_spacing: Tuple[float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = hann(detector_width, detector_spacing_width)\n    filter_2D = np.tile(filter_1D, (number_of_projections, 1))\n\n    return filter_2D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/filters/#pyronn.ct_reconstruction.helpers.filters.filters.hann_3D","title":"pyronn.ct_reconstruction.helpers.filters.filters.hann_3D","text":"<pre><code>hann_3D(detector_shape: Tuple[int, int, int], detector_spacing: Tuple[float, float, float], number_of_projections: int) -&gt; np.array\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/filters.py</code> <pre><code>def hann_3D(\n    detector_shape: Tuple[int, int, int],\n    detector_spacing: Tuple[float, float, float],\n    number_of_projections: int,\n) -&gt; np.array:\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    detector_width = detector_shape[-1]\n    detector_spacing_width = detector_spacing[-1]\n\n    filter_1D = hann(detector_width, detector_spacing_width)\n    filter_3D = np.tile(\n        filter_1D.reshape(1, 1, detector_width), (number_of_projections, 1, 1)\n    )\n\n    return filter_3D\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/weights/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/filters/weights.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/filters/weights/#pyronn.ct_reconstruction.helpers.filters.weights.cosine_weights_3d","title":"pyronn.ct_reconstruction.helpers.filters.weights.cosine_weights_3d","text":"<pre><code>cosine_weights_3d(geometry)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/weights.py</code> <pre><code>def cosine_weights_3d(geometry):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    cu = -(geometry.detector_shape[-1] - 1) / 2 * geometry.detector_spacing[-1]\n    cv = -(geometry.detector_shape[-2] - 1) / 2 * geometry.detector_spacing[-2]\n    sd2 = geometry.source_detector_distance ** 2\n\n    w = np.zeros((geometry.detector_shape[-2], geometry.detector_shape[-1]), dtype=np.float32)\n\n    for v in range(0, geometry.detector_shape[-2]):\n        dv = (v * geometry.detector_spacing[-2] + cv) ** 2\n        for u in range(0, geometry.detector_shape[-1]):\n            du = (u * geometry.detector_spacing[-1] + cu) ** 2\n            w[v, u] = geometry.source_detector_distance / np.sqrt(sd2 + dv + du)\n\n    return np.flip(w)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/weights/#pyronn.ct_reconstruction.helpers.filters.weights.parker_weights_3d","title":"pyronn.ct_reconstruction.helpers.filters.weights.parker_weights_3d","text":"<pre><code>parker_weights_3d(geometry)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/weights.py</code> <pre><code>def parker_weights_3d(geometry):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    weights = np.flip(parker_weights_2d(geometry), axis=1)\n    weights = np.array(np.expand_dims(weights, axis=1), dtype=np.float32)\n    return weights\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/weights/#pyronn.ct_reconstruction.helpers.filters.weights.parker_weights_2d","title":"pyronn.ct_reconstruction.helpers.filters.weights.parker_weights_2d","text":"<pre><code>parker_weights_2d(geometry)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/weights.py</code> <pre><code>def parker_weights_2d(geometry):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    number_of_projections = geometry.number_of_projections\n    angular_range = geometry.angular_range[1] - geometry.angular_range[0]\n    detector_shape = geometry.detector_shape\n    detector_spacing = geometry.detector_spacing\n    # detector_origin = geometry.detector_origin\n    source_detector_distance = geometry.source_detector_distance\n    fan_angle = geometry.fan_angle\n\n    weights = np.ones((number_of_projections, detector_shape[-1]))\n    angular_increment = angular_range / number_of_projections\n    beta = 0\n    beta = ((np.pi + 2*fan_angle) - angular_range) / 2.0 # adds offset\n\n    for beta_idx in range(weights.shape[0]):\n        for gamma_idx in range(weights.shape[1]):\n                # calculate correct pos on detector and current angle\n                gamma_angle = gamma_idx * detector_spacing[-1]# + detector_origin[-1]\n                gamma_angle = np.arctan(gamma_angle / source_detector_distance)\n\n                # check if rays sampled twice and create weight volume\n                if 0 &lt;= beta and beta &lt;= 2*(fan_angle - gamma_angle):\n                    val = np.sin( ((np.pi/4.0) * beta) / (fan_angle - gamma_angle) ) ** 2\n                    if not np.isnan(val):\n                        weights[beta_idx, gamma_idx] = val\n\n                elif 2*(fan_angle - gamma_angle) &lt; beta and beta &lt; np.pi - 2*gamma_angle:\n                    weights[beta_idx, gamma_idx] = 1.0\n\n                elif np.pi - 2*gamma_angle &lt;= beta and beta &lt;= np.pi + 2*fan_angle:\n                    val = np.sin((np.pi/4.0) * ((np.pi + 2*fan_angle - beta) / (gamma_angle + fan_angle))) ** 2\n                    if not np.isnan(val):\n                        weights[beta_idx, gamma_idx] = val\n\n                else:\n                    weights[beta_idx, gamma_idx] = 0\n\n        beta += angular_increment\n\n    # additional scaling factor\n    scale_factor = (angular_range + angular_range  / number_of_projections) / np.pi\n\n    return weights * scale_factor\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/filters/weights/#pyronn.ct_reconstruction.helpers.filters.weights.riess_weights_2d","title":"pyronn.ct_reconstruction.helpers.filters.weights.riess_weights_2d","text":"<pre><code>riess_weights_2d(geometry)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/filters/weights.py</code> <pre><code>def riess_weights_2d(geometry):\n\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    delta_x = geometry.angular_range - np.pi # overscan\n\n    def eta(beta, gamma_angle):\n        return np.sin( (np.pi/2.0) * (np.pi+delta_x-beta) / (delta_x-2*gamma_angle) ) ** 2\n\n    def zeta(beta, gamma_angle):\n        return np.sin( (np.pi/2.0) * beta / (delta_x+2*gamma_angle) ) ** 2\n\n    weights = np.ones((geometry.number_of_projections, geometry.detector_shape[-1]))\n    angular_increment = geometry.angular_range / geometry.number_of_projections\n    beta = 0\n\n    for beta_idx in range(weights.shape[0]):\n        for gamma_idx in range(weights.shape[1]):\n                # calculate correct pos on detector and current angle\n                gamma_angle = gamma_idx * geometry.detector_spacing[-1] + geometry.detector_origin[-1]\n                gamma_angle = np.arctan(gamma_angle / geometry.source_detector_distance)\n\n                if np.pi + 2*gamma_angle &lt;= beta and beta &lt;= np.pi + delta_x:\n                    val = eta(beta, gamma_angle)\n                    if not np.isnan(val):\n                        weights[beta_idx, gamma_idx] = val\n\n                if np.pi + 2*(delta_x - gamma_angle) &lt;= beta and beta &lt;= np.pi + delta_x:\n                    val = 2 - eta(beta, gamma_angle)\n                    if not np.isnan(val):\n                        weights[beta_idx, gamma_idx] = val\n\n                if 0 &lt;= beta and beta &lt;= 2*gamma_angle + delta_x:\n                    val = zeta(beta, gamma_angle)\n                    if not np.isnan(val):\n                        weights[beta_idx, gamma_idx] = val\n\n                if 0 &lt;= beta and beta &lt;= -delta_x - 2*gamma_angle:\n                    val = 2 - zeta(beta, gamma_angle)\n                    if not np.isnan(val):\n                        weights[beta_idx, gamma_idx] = val\n\n        beta += angular_increment\n\n    # additional scaling factor\n    scale_factor = geometry.angular_range / np.pi\n    return weights * scale_factor\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/misc/general_utils/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/misc/general_utils.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/misc/general_utils/#pyronn.ct_reconstruction.helpers.misc.general_utils.fibonacci_sphere","title":"pyronn.ct_reconstruction.helpers.misc.general_utils.fibonacci_sphere","text":"<pre><code>fibonacci_sphere(n)\n</code></pre> <p>Calculation of the fibonacci distribution on a unit sphere with n samples. :param n: Number of samples on the sphere :return: The entered coordinates seperated to x,y,z components</p> Source code in <code>pyronn/ct_reconstruction/helpers/misc/general_utils.py</code> <pre><code>def fibonacci_sphere(n):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Calculation of the fibonacci distribution on a unit sphere with n samples.\n    :param n: Number of samples on the sphere\n    :return: The entered coordinates seperated to x,y,z components\n    '''\n    goldenRatio = (1 + 5**0.5)/2\n    i = np.arange(0, n)\n    theta = (2 *np.pi * i / goldenRatio)  %(2*np.pi) # to radian  # in range [0\u00b0,360\u00b0]\n    phi = np.arccos(1 - 2*(i+0.5)/n)  #/2  # in range [1\u00b0,179\u00b0]\n    x,z, y = np.cos(theta) * np.sin(phi), np.sin(theta) * np.sin(phi), np.cos(phi)\n    return np.vstack([x,y,z]).T\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/misc/general_utils/#pyronn.ct_reconstruction.helpers.misc.general_utils.rotation_matrix_from_points","title":"pyronn.ct_reconstruction.helpers.misc.general_utils.rotation_matrix_from_points","text":"<pre><code>rotation_matrix_from_points(p1, p2)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/misc/general_utils.py</code> <pre><code>def rotation_matrix_from_points(p1, p2):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    p1 = np.array(p1) / np.linalg.norm(p1)\n    p2 = np.array(p2) / np.linalg.norm(p2)\n\n    axis = np.cross(p1, p2)\n    axis_length = np.linalg.norm(axis)\n    if axis_length &lt; 1e-5:\n        if np.dot(p1, p2) &gt; 0:\n            return np.eye(3)\n        else:\n            axis = np.array([p1[1], -p1[0], 0])\n            if np.linalg.norm(axis) == 0:\n                axis = np.array([p1[2], 0, -p1[0]])\n            axis = axis / np.linalg.norm(axis)\n            theta = np.pi\n    else:\n        axis = axis / axis_length\n\n    cos_theta = np.dot(p1, p2)\n    sin_theta = np.sqrt(1 - cos_theta ** 2)\n\n    K = np.array([[0, -axis[2], axis[1]],\n                  [axis[2], 0, -axis[0]],\n                  [-axis[1], axis[0], 0]])\n    R = np.eye(3) + sin_theta * K + (1 - cos_theta) * np.dot(K, K)\n\n    return R\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/misc/general_utils/#pyronn.ct_reconstruction.helpers.misc.general_utils.fft_and_ifft","title":"pyronn.ct_reconstruction.helpers.misc.general_utils.fft_and_ifft","text":"<pre><code>fft_and_ifft(sinogram, filter)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/misc/general_utils.py</code> <pre><code>def fft_and_ifft(sinogram, filter):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    if pyronn.read_backend() == 'torch':\n        import torch\n        if not isinstance(sinogram, torch.Tensor):\n            sinogram = torch.tensor(sinogram).cuda()\n        if not isinstance(filter, torch.Tensor):\n            filter = torch.tensor(filter).cuda()\n\n        x = torch.fft.fft(sinogram, dim=-1, norm='ortho')\n        x = torch.multiply(x, filter)\n        x = torch.fft.ifft(x, dim=-1, norm='ortho').real\n        return x\n    elif pyronn.read_backend() == 'tensorflow':\n        import tensorflow as tf\n        sino_freq = tf.signal.fft(tf.cast(sinogram, dtype=tf.complex64))\n        sino_filtered_freq = tf.multiply(sino_freq, tf.cast(filter, dtype=tf.complex64))\n        sinogram_filtered = tf.math.real(tf.signal.ifft(sino_filtered_freq))\n        return sinogram_filtered\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_2d/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_2d.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_2d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_2d.circle","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_2d.circle","text":"<pre><code>circle(shape, pos, radius, value=1.0)\n</code></pre> <pre><code>Creates a simple circle primitive.\n</code></pre> <p>Args:     shape:      Shape (in [Y, X])     pos:        Center (in [Y, X]) from upper left corner     radius:     Radius     value:      Value</p> <p>Returns:</p> Type Description <p>np.array filled with circle</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_2d.py</code> <pre><code>def circle(shape, pos, radius, value=1.0):\n    \"\"\"\n        Creates a simple circle primitive.\n    Args:\n        shape:      Shape (in [Y, X])\n        pos:        Center (in [Y, X]) from upper left corner\n        radius:     Radius\n        value:      Value\n\n    Returns:\n        np.array filled with circle\n    \"\"\"\n    # create meshgrid of coords\n    xx, yy = np.mgrid[:shape[0], :shape[1]].astype(dtype=np.float32)\n\n    # calc squared distance to pos\n    circle = (xx - pos[1]) ** 2 + (yy - pos[0]) ** 2\n\n    return (circle &lt;= radius ** 2) *  (np.float32)(value)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_2d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_2d.ellipse","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_2d.ellipse","text":"<pre><code>ellipse(shape, pos, half_axes, value=1.0, phi=0.0)\n</code></pre> <pre><code>Creates a simple ellipse primitive.\n</code></pre> <p>Args:     shape:          Shape (in [Y, X])     pos:            Center (in [Y, X]) from upper left corner     half_axes:      Half axes of the ellipse (in [b, a])     value:          Value     phi:            Rotation Angle in radians</p> <p>Returns:</p> Type Description <p>np.array filled with ellipse</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_2d.py</code> <pre><code>def ellipse(shape, pos, half_axes, value=1.0, phi=0.0):\n    \"\"\"\n        Creates a simple ellipse primitive.\n    Args:\n        shape:          Shape (in [Y, X])\n        pos:            Center (in [Y, X]) from upper left corner\n        half_axes:      Half axes of the ellipse (in [b, a])\n        value:          Value\n        phi:            Rotation Angle in radians\n\n    Returns:\n        np.array filled with ellipse\n    \"\"\"\n    # create meshgrid of coords\n    xx, yy = np.mgrid[:shape[0], :shape[1]].astype(dtype=np.float32)\n\n    # move to pos\n    xc = (xx - pos[1])\n    yc = (yy - pos[0])\n\n    # rotate\n    xx = xc * np.cos(phi) + yc * np.sin(phi)\n    yy = yc * np.cos(phi) - xc * np.sin(phi)\n\n    a = half_axes[1]\n    b = half_axes[0]\n\n    # calc squared distance to pos\n    ellipse_points = (xx ** 2) / (a ** 2) + (yy ** 2) / (b ** 2)\n\n    return (ellipse_points &lt;= 1) * value\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_2d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_2d.rect","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_2d.rect","text":"<pre><code>rect(shape, pos, size, value=1.0)\n</code></pre> <pre><code>Creates a simple rect primitive.\n</code></pre> <p>Args:     shape:      Shape (in [Y, X])     pos:        Pos (upper left corner) (in [Y, X]) from upper left corner     size:       Size  (in [Y, X])     value:      Value</p> <p>Returns:</p> Type Description <p>np.array filled with rectangle</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_2d.py</code> <pre><code>def rect(shape, pos, size, value=1.0):\n    \"\"\"\n        Creates a simple rect primitive.\n    Args:\n        shape:      Shape (in [Y, X])\n        pos:        Pos (upper left corner) (in [Y, X]) from upper left corner\n        size:       Size  (in [Y, X])\n        value:      Value\n\n    Returns:\n        np.array filled with rectangle\n    \"\"\"\n    # create array and populate it with value\n    rectangle = np.zeros(shape, dtype=np.float32)\n    rectangle[pos[0]:pos[0] + size[0], pos[1]:pos[1] + size[1]] = value\n\n    return rectangle\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_sphere","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_sphere","text":"<pre><code>place_sphere(grid, pos, radius, value=1.0)\n</code></pre> <p>Updates an existing 3D grid by placing a spherical object within it.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <p>The existing 3D numpy array (meshgrid) to update.</p> required <code>pos</code> <p>Center of the sphere (in [Z, Y, X]).</p> required <code>radius</code> <p>Radius of the sphere.</p> required <code>value</code> <p>Value to fill the sphere with.</p> <code>1.0</code> <p>Returns:</p> Type Description <p>None; the function updates the grid in place.</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def place_sphere(grid, pos, radius, value=1.0):\n    \"\"\"\n    Updates an existing 3D grid by placing a spherical object within it.\n\n    Args:\n        grid:   The existing 3D numpy array (meshgrid) to update.\n        pos:    Center of the sphere (in [Z, Y, X]).\n        radius: Radius of the sphere.\n        value:  Value to fill the sphere with.\n\n    Returns:\n        None; the function updates the grid in place.\n    \"\"\"\n\n    # Ensure the grid is a numpy array\n    grid = np.asarray(grid)\n\n    # Grid shape\n    shape = grid.shape\n\n    # Create meshgrid of coords based on the grid's shape\n    xx, yy, zz = np.mgrid[0:shape[0], 0:shape[1], 0:shape[2]]\n\n    # Calculate squared distance to pos\n    circle = (xx - pos[2])**2 + (yy - pos[1])**2 + (zz - pos[0])**2\n\n    # Update grid in place where the condition is met\n    grid[circle &lt;= radius**2] = value\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_cube","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_cube","text":"<pre><code>place_cube(grid, pos, size, value=1.0)\n</code></pre> <p>Updates an existing 3D grid by placing a cube object within it.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <p>The existing 3D numpy array (meshgrid) to update.</p> required <code>pos</code> <p>Position of the cube's upper left corner (in [Z, Y, X]).</p> required <code>size</code> <p>Size of the cube (in [Z, Y, X]).</p> required <code>value</code> <p>Value to fill the cube with.</p> <code>1.0</code> <p>Returns:</p> Type Description <p>None; the function updates the grid in place.</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def place_cube(grid, pos, size, value=1.0):\n    \"\"\"\n    Updates an existing 3D grid by placing a cube object within it.\n\n    Args:\n        grid:   The existing 3D numpy array (meshgrid) to update.\n        pos:    Position of the cube's upper left corner (in [Z, Y, X]).\n        size:   Size of the cube (in [Z, Y, X]).\n        value:  Value to fill the cube with.\n\n    Returns:\n        None; the function updates the grid in place.\n    \"\"\"\n    # Ensure pos and size are within the grid bounds\n    for i in range(3):\n        if pos[i] &lt; 0 or pos[i] + size[i] &gt; grid.shape[i]:\n            raise ValueError(f\"Cube at position {pos} with size {size} exceeds grid bounds.\")\n\n    # Update the grid in place\n    grid[pos[0]:pos[0]+size[0], pos[1]:pos[1]+size[1], pos[2]:pos[2]+size[2]] = value\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.rotate_point_around_z","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.rotate_point_around_z","text":"<pre><code>rotate_point_around_z(x, y, z, angle)\n</code></pre> <p>Rotate a point around the Z-axis by a given angle.</p> <p>Parameters:</p> Name Type Description Default <code>x,</code> <code>(y, z)</code> <p>Coordinates of the point.</p> required <code>angle</code> <p>Rotation angle in radians.</p> required <p>Returns:</p> Type Description <p>Rotated coordinates (x', y', z').</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def rotate_point_around_z(x, y, z, angle):\n    \"\"\"\n    Rotate a point around the Z-axis by a given angle.\n\n    Args:\n        x, y, z: Coordinates of the point.\n        angle: Rotation angle in radians.\n\n    Returns:\n        Rotated coordinates (x', y', z').\n    \"\"\"\n    cos_angle = np.cos(angle)\n    sin_angle = np.sin(angle)\n    x_rotated = x * cos_angle - y * sin_angle\n    y_rotated = x * sin_angle + y * cos_angle\n    return x_rotated, y_rotated, z\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_cube_with_rotation","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_cube_with_rotation","text":"<pre><code>place_cube_with_rotation(grid, pos, size, value=1.0, angle=None)\n</code></pre> <p>Updates an existing 3D grid by placing a cube object within it, potentially rotated around the Z-axis.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <p>The existing 3D numpy array (meshgrid) to update.</p> required <code>pos</code> <p>Position of the cube's upper left corner (in [Z, Y, X]).</p> required <code>size</code> <p>Size of the cube (in [Z, Y, X]).</p> required <code>value</code> <p>Value to fill the cube with.</p> <code>1.0</code> <code>angle</code> <p>Rotation angle in radians around the Z-axis. If None, a random angle is chosen.</p> <code>None</code> <p>Returns:</p> Type Description <p>None; the function updates the grid in place.</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def place_cube_with_rotation(grid, pos, size, value=1.0, angle=None):\n    \"\"\"\n    Updates an existing 3D grid by placing a cube object within it, potentially rotated around the Z-axis.\n\n    Args:\n        grid:   The existing 3D numpy array (meshgrid) to update.\n        pos:    Position of the cube's upper left corner (in [Z, Y, X]).\n        size:   Size of the cube (in [Z, Y, X]).\n        value:  Value to fill the cube with.\n        angle:  Rotation angle in radians around the Z-axis. If None, a random angle is chosen.\n\n    Returns:\n        None; the function updates the grid in place.\n    \"\"\"\n    if angle is None:\n        angle = np.random.uniform(0, 2*np.pi)  # Random angle if not specified\n\n    xx,yy,zz = np.mgrid[0:grid.shape[0], 0:grid.shape[1], 0:grid.shape[2]]\n\n    # Center of the cube\n    center = np.array(pos) + np.array(size) / 2\n\n    # Rotate grid points around the Z-axis in the opposite direction\n    try:\n        xx_rotated, yy_rotated, _ = rotate_point_around_z(xx - center[2], yy - center[1], 0, -angle)\n        # Adjust back to grid coordinates\n        xx_rotated += center[2]\n        yy_rotated += center[1]\n         # Check if rotated points are inside the unrotated cube's bounds\n        inside_cube = (\n            (xx_rotated &gt;= pos[2]) &amp; (xx_rotated &lt;= pos[2] + size[2]) &amp;\n            (yy_rotated &gt;= pos[1]) &amp; (yy_rotated &lt;= pos[1] + size[1]) &amp;\n            (zz &gt;= pos[0]) &amp; (zz &lt;= pos[0] + size[0])\n        )\n\n        # Update grid where the condition is met\n        grid[inside_cube] = value\n    except ValueError:\n        # Calculate start and end indices for each dimension, ensuring they are within the grid bounds\n        start_indices = [max(0, p) for p in pos]\n        end_indices = [min(pos[i] + size[i], grid.shape[i]) for i in range(3)]\n\n        # Update the grid within the calculated indices\n        grid[\n            start_indices[0]:end_indices[0],\n            start_indices[1]:end_indices[1],\n            start_indices[2]:end_indices[2]\n        ] = value\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_ellipsoid_with_rotation","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_ellipsoid_with_rotation","text":"<pre><code>place_ellipsoid_with_rotation(grid, pos, radii, value=1.0, angle=None)\n</code></pre> <p>Updates an existing 3D grid by placing a randomly rotated ellipsoid object within it.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <p>The existing 3D numpy array (meshgrid) to update.</p> required <code>pos</code> <p>Center of the ellipsoid (in [Z, Y, X]).</p> required <code>radii</code> <p>Radii of the ellipsoid (in [Z, Y, X]).</p> required <code>value</code> <p>Value to fill the ellipsoid with.</p> <code>1.0</code> <code>angle</code> <p>Rotation angle in radians around the Z-axis. If None, a random angle is chosen.</p> <code>None</code> <p>Returns:</p> Type Description <p>None; the function updates the grid in place.</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def place_ellipsoid_with_rotation(grid, pos, radii, value=1.0, angle=None):\n    \"\"\"\n    Updates an existing 3D grid by placing a randomly rotated ellipsoid object within it.\n\n    Args:\n        grid:   The existing 3D numpy array (meshgrid) to update.\n        pos:    Center of the ellipsoid (in [Z, Y, X]).\n        radii:  Radii of the ellipsoid (in [Z, Y, X]).\n        value:  Value to fill the ellipsoid with.\n        angle:  Rotation angle in radians around the Z-axis. If None, a random angle is chosen.\n\n    Returns:\n        None; the function updates the grid in place.\n    \"\"\"\n    if angle is None:\n        angle = np.random.uniform(0, 2*np.pi)  # Random angle if not specified\n\n    zz, yy, xx = np.mgrid[0:grid.shape[0], 0:grid.shape[1], 0:grid.shape[2]]\n\n    # Rotate grid points around the Z-axis in the opposite direction\n    xx_rotated, yy_rotated, _ = rotate_point_around_z(xx - pos[2], yy - pos[1], 0, -angle)\n\n    # Adjust back to original positions\n    xx_rotated += pos[2]\n    yy_rotated += pos[1]\n\n    # Check if rotated points are inside the ellipsoid\n    inside_ellipsoid = (\n        ((xx_rotated - pos[2])**2 / radii[2]**2) +\n        ((yy_rotated - pos[1])**2 / radii[1]**2) +\n        ((zz - pos[0])**2 / radii[0]**2)\n    ) &lt;= 1\n\n    # Update grid where the condition is met\n    grid[inside_ellipsoid] = value\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_cylinder_with_rotation","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_cylinder_with_rotation","text":"<pre><code>place_cylinder_with_rotation(grid, pos, height, radius, value=1.0, angle=None)\n</code></pre> <p>Updates an existing 3D grid by placing a randomly rotated cylinder object within it. Args:     grid: The existing 3D numpy array (meshgrid) to update.     pos: Center of the base of the cylinder (in [Z, Y, X]).     height: Height of the cylinder along the Z-axis.     radius: Radius of the cylinder in the XY plane.     value: Value to fill the cylinder with.     angle: Rotation angle in radians around the Z-axis. If None, a random angle is chosen. Returns:     None; the function updates the grid in place.</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def place_cylinder_with_rotation(grid, pos, height, radius, value=1.0, angle=None):\n    \"\"\"\n    Updates an existing 3D grid by placing a randomly rotated cylinder object within it.\n    Args:\n        grid: The existing 3D numpy array (meshgrid) to update.\n        pos: Center of the base of the cylinder (in [Z, Y, X]).\n        height: Height of the cylinder along the Z-axis.\n        radius: Radius of the cylinder in the XY plane.\n        value: Value to fill the cylinder with.\n        angle: Rotation angle in radians around the Z-axis. If None, a random angle is chosen.\n    Returns:\n        None; the function updates the grid in place.\n    \"\"\"\n    if angle is None:\n        angle = np.random.uniform(0, 2*np.pi)  # Random angle if not specified\n\n    # Create meshgrid\n    zz, yy, xx = np.mgrid[0:grid.shape[0], 0:grid.shape[1], 0:grid.shape[2]]\n\n    # Rotate grid points around the Z-axis in the opposite direction to simulate cylinder rotation\n    xx_rotated, yy_rotated, _ = rotate_point_around_z(xx - pos[2], yy - pos[1], zz, -angle)\n\n    # Adjust back to original positions\n    xx_rotated += pos[2]\n    yy_rotated += pos[1]\n\n    # Check if rotated points are within the cylinder\n    inside_cylinder = ((xx_rotated - pos[2])**2 + (yy_rotated - pos[1])**2 &lt;= radius**2) &amp;                      (zz &gt;= pos[0]) &amp; (zz &lt;= pos[0] + height)\n\n    # Update grid where the condition is met\n    grid[inside_cylinder] = value\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_pyramid","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.place_pyramid","text":"<pre><code>place_pyramid(grid, base_center, base_size, height, value=1.0)\n</code></pre> <p>Places an axis-aligned pyramid into a 3D grid.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <p>3D numpy array representing the grid.</p> required <code>base_center</code> <p>Center of the pyramid's base in the grid (z, y, x).</p> required <code>base_size</code> <p>Side length of the pyramid's square base.</p> required <code>height</code> <p>Height of the pyramid.</p> required <code>value</code> <p>Value to fill the pyramid with.</p> <code>1.0</code> <p>Returns:</p> Type Description <p>None; the grid is modified in place.</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def place_pyramid(grid, base_center, base_size, height, value=1.0):\n    \"\"\"\n    Places an axis-aligned pyramid into a 3D grid.\n\n    Args:\n        grid: 3D numpy array representing the grid.\n        base_center: Center of the pyramid's base in the grid (z, y, x).\n        base_size: Side length of the pyramid's square base.\n        height: Height of the pyramid.\n        value: Value to fill the pyramid with.\n\n    Returns:\n        None; the grid is modified in place.\n    \"\"\"\n    zz, yy, xx = np.mgrid[0:grid.shape[0], 0:grid.shape[1], 0:grid.shape[2]]\n\n    # Calculate distances from the base center in the XY plane\n    dx = np.abs(xx - base_center[2])\n    dy = np.abs(yy - base_center[1])\n\n    # Calculate the maximum allowable distance in the XY plane at each Z level\n    max_dist = base_size / 2 * (1 - zz / height)\n\n    # Determine points inside the pyramid\n    inside_pyramid = (dx &lt;= max_dist) &amp; (dy &lt;= max_dist) &amp; (zz &lt;= height)\n\n    # Update the grid\n    grid[inside_pyramid] = value\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.visualize_grid","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.visualize_grid","text":"<pre><code>visualize_grid(grid)\n</code></pre> <p>Visualizes a 3D grid using matplotlib, plotting points where the grid value is non-zero.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <p>The 3D numpy array to visualize.</p> required Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def visualize_grid(grid):\n    \"\"\"\n    Visualizes a 3D grid using matplotlib, plotting points where the grid value is non-zero.\n\n    Args:\n        grid: The 3D numpy array to visualize.\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Get the coordinates of points where the grid value is non-zero\n    z, y, x = grid.nonzero()\n\n    # Use scatter plot for these points\n    ax.scatter(x, y, z, c='red', marker='o')\n\n    # Set labels and title\n    ax.set_xlabel('X Axis')\n    ax.set_ylabel('Y Axis')\n    ax.set_zlabel('Z Axis')\n    ax.set_title('3D Grid Visualization')\n\n    # plt.show()\n    plt.savefig(f'random_object.png', dpi=150, transparent=False, bbox_inches='tight')\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/primitives_3d/#pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.generate_3D_primitives","title":"pyronn.ct_reconstruction.helpers.phantoms.primitives_3d.generate_3D_primitives","text":"<pre><code>generate_3D_primitives(volume_shape, number_of_primitives)\n</code></pre> <p>Generates a 3D phantom composed of a specified number of random geometric primitives. The primitives are added to the phantom with random positions, orientations, sizes, and intensities. The method returns both the phantom and its sinogram as PyTorch tensors.</p> <p>Parameters: - volume_shape: shape of the phantom - number_of_primitives (int, optional): The number of geometric primitives to include in the phantom. Defaults to 6.</p> <p>Returns: - numpy.array: The 3D phantom.</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/primitives_3d.py</code> <pre><code>def generate_3D_primitives(volume_shape, number_of_primitives):\n    \"\"\"\n    Generates a 3D phantom composed of a specified number of random geometric primitives. The primitives are added\n    to the phantom with random positions, orientations, sizes, and intensities. The method returns both\n    the phantom and its sinogram as PyTorch tensors.\n\n    Parameters:\n    - volume_shape: shape of the phantom\n    - number_of_primitives (int, optional): The number of geometric primitives to include in the phantom.\n    Defaults to 6.\n\n    Returns:\n    - numpy.array: The 3D phantom.\n    \"\"\"\n    grid = np.zeros(volume_shape)\n\n    for i in range(number_of_primitives):\n        object_type = random.choice([\"ellipsoid\", \"sphere\", \"cube\", \"pyramid\", \"cylinder\", \"rectangle\"])\n        pos = np.random.randint(0, volume_shape[0], 3)\n        intensitiy_value = np.random.uniform(0.4, 1.0, 1)\n        print(f\"{i}th Random choice was {object_type}, placed at {pos} with intensity {intensitiy_value}.\")\n\n        if object_type == \"ellipsoid\":\n            ellipsoid_radii = np.random.randint(1, int(volume_shape[0] / 5),\n                                                3)  # Radii along Z, Y, X axes\n            place_ellipsoid_with_rotation(grid, pos, ellipsoid_radii, value=intensitiy_value)\n        elif object_type == \"sphere\":\n            radius = np.random.randint(1, int(volume_shape[0] / 5), 1)  # Radius\n            place_sphere(grid, pos, radius, value=intensitiy_value)\n        elif object_type == 'rectangle':\n            cube_size = np.random.randint(1, int(volume_shape[0] / 5), 3)  # Size of the cube\n            place_cube_with_rotation(grid, pos, cube_size, value=intensitiy_value)\n        elif object_type == 'cube':\n            cube_size = np.random.randint(1, int(volume_shape[0] / 5), 1)  # Size of the cube\n            place_cube_with_rotation(grid, pos, (cube_size[0], cube_size[0], cube_size[0]), value=intensitiy_value)\n        elif object_type == 'pyramid':\n            base_size = np.random.randint(1, int(volume_shape[0] / 5), 1)  # Length of the base's side\n            height = np.random.randint(1, int(volume_shape[0] / 5), 1)  # Height of the pyramid\n            # Place the pyramid in the grid\n            place_pyramid(grid, pos, base_size, height, intensitiy_value)\n        else:  # 'cylinder'\n            cylinder_height = np.random.randint(1, int(volume_shape[0] / 5), 1)\n            cylinder_radius = np.random.randint(1, int(volume_shape[0] / 5), 1)\n            place_cylinder_with_rotation(grid, pos, cylinder_height, cylinder_radius, value=intensitiy_value)\n    return grid\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/shepp_logan/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/phantoms/shepp_logan.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/phantoms/shepp_logan/#pyronn.ct_reconstruction.helpers.phantoms.shepp_logan.shepp_logan","title":"pyronn.ct_reconstruction.helpers.phantoms.shepp_logan.shepp_logan","text":"<pre><code>shepp_logan(shape)\n</code></pre> <pre><code>Creates the Shepp Logan Phantom.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>shape</code> <p>Shape (in [Y, X]) of Shepp Logan phantom to create.</p> required <p>Returns:</p> Type Description <p>Shepp Logan of shape as np.array</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/shepp_logan.py</code> <pre><code>def shepp_logan(shape):\n    \"\"\"\n        Creates the Shepp Logan Phantom.\n\n    Args:\n        shape: Shape (in [Y, X]) of Shepp Logan phantom to create.\n\n    Returns:\n        Shepp Logan of shape as np.array\n\n    \"\"\"\n    # Definition of Shepp Logan Phantom\n    # Ellipse\tCenter\t         Major Axis    Minor Axis    Phi     Gray Level\n    # a\t        (0,0)\t         0.69\t       0.92\t         0\t     2\n    # b\t        (0,-0.0184)\t     0.6624\t       0.874\t     0\t     -0.98\n    # c\t        (0.22,0)\t     0.11\t       0.31\t         -18\u00b0\t -0.02\n    # d\t        (-0.22,0)\t     0.16\t       0.41\t         18\u00b0\t -0.02\n    # e\t        (0,0.35)\t     0.21\t       0.25\t         0\t     0.01\n    # f\t        (0,0.1)\t         0.046\t       0.046\t     0\t     0.01\n    # g\t        (0,-0.1)\t     0.046\t       0.046\t     0\t     0.01\n    # h\t        (-0.08,-0.605)\t 0.046\t       0.023\t     0\t     0.01\n    # i\t        (0,-0.605)\t     0.023\t       0.023\t     0\t     0.01\n    # j\t        (0.06,-0.605)\t 0.023\t       0.046\t     0\t     0.01\n    shepp_logan = np.zeros(shape)\n\n    # create meshgrid of coords\n    yy_base, xx_base = np.mgrid[:shape[0], :shape[1]]\n\n    # center at 0, 0 and normalize\n    xx_base = (xx_base - (shape[1] - 1) / 2) / ((shape[1] - 1) / 2)\n    yy_base = (yy_base - (shape[0] - 1) / 2) / ((shape[0] - 1) / 2)\n\n    # definition of ellipses as np.array:\n    el_params = np.array([[0     ,0       ,0.69     ,0.92 ,0              ,2     ],\n                          [0     ,-0.0184 ,0.6624 ,0.874 ,0              ,-0.98 ],\n                          [0.22  ,0       ,0.11     ,0.31 ,np.radians(-18) ,-0.02 ],\n                          [-0.22 ,0       ,0.16     ,0.41 ,np.radians( 18) ,-0.02 ],\n                          [0     ,0.35   ,0.21     ,0.25 ,0              ,0.01  ],\n                          [0     ,0.1     ,0.046 ,0.046 ,0              ,0.01  ],\n                          [0     ,-0.1    ,0.046 ,0.046 ,0              ,0.01  ],\n                          [-0.08 ,-0.605  ,0.046 ,0.023 ,0              ,0.01  ],\n                          [0     ,-0.605  ,0.023 ,0.023 ,0              ,0.01  ],\n                          [0.06  ,-0.605  ,0.023 ,0.046 ,0              ,0.01  ]])\n\n    # create ellipses and sum up\n    for i in range(el_params.shape[0]):\n        # get params:\n        x_pos = el_params[i][0]\n        y_pos = el_params[i][1]\n        a     = el_params[i][2]\n        b     = el_params[i][3]\n        phi   = el_params[i][4]\n        value = el_params[i][5]\n\n        # move to pos\n        xc = (xx_base - x_pos)\n        yc = (yy_base - y_pos)\n\n        # rotate\n        xx = xc * np.cos(phi) + yc * np.sin(phi)\n        yy = yc * np.cos(phi) - xc * np.sin(phi)\n\n        # calc squared distance to pos\n        ellipse_points = (xx ** 2) / (a ** 2) + (yy ** 2) / (b ** 2)\n\n        # sum up\n        shepp_logan = shepp_logan + (ellipse_points &lt;= 1) * value\n\n    return np.flip(shepp_logan, axis=0)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/shepp_logan/#pyronn.ct_reconstruction.helpers.phantoms.shepp_logan.shepp_logan_enhanced","title":"pyronn.ct_reconstruction.helpers.phantoms.shepp_logan.shepp_logan_enhanced","text":"<pre><code>shepp_logan_enhanced(shape)\n</code></pre> <pre><code>Creates a contrast enhanced Shepp Logan Phantom.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>shape</code> <p>Shape (in [Y, X]) of phantom to create.</p> required <p>Returns:</p> Type Description <p>Phantom of shape as np.array</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/shepp_logan.py</code> <pre><code>def shepp_logan_enhanced(shape):\n    \"\"\"\n        Creates a contrast enhanced Shepp Logan Phantom.\n\n    Args:\n        shape: Shape (in [Y, X]) of phantom to create.\n\n    Returns:\n        Phantom of shape as np.array\n\n    \"\"\"\n    shepp_logan = np.zeros(shape, dtype=np.float32)\n\n    # create meshgrid of coords\n    yy_base, xx_base = np.mgrid[:shape[0], :shape[1]]\n\n    # center at 0, 0 and normalize\n    xx_base = (xx_base - (shape[1] - 1) / 2) / ((shape[1] - 1) / 2)\n    yy_base = (yy_base - (shape[0] - 1) / 2) / ((shape[0] - 1) / 2)\n\n    # definition of ellipses with enhanced contrast values as np.array:\n    el_params = np.array([[0     ,0       ,0.69     ,0.92 ,0              ,1    ],\n                          [0     ,-0.0184 ,0.6624 ,0.874 ,0              ,-0.8 ],\n                          [0.22  ,0       ,0.11     ,0.31 ,np.radians(-18) ,-0.2 ],\n                          [-0.22 ,0       ,0.16     ,0.41 ,np.radians( 18) ,-0.2 ],\n                          [0     ,0.35   ,0.21     ,0.25 ,0              ,0.1  ],\n                          [0     ,0.1     ,0.046 ,0.046 ,0              ,0.1  ],\n                          [0     ,-0.1    ,0.046 ,0.046 ,0              ,0.1  ],\n                          [-0.08 ,-0.605  ,0.046 ,0.023 ,0              ,0.1  ],\n                          [0     ,-0.605  ,0.023 ,0.023 ,0              ,0.1  ],\n                          [0.06  ,-0.605  ,0.023 ,0.046 ,0              ,0.1  ]])\n\n    # create ellipses and sum up\n    for i in range(el_params.shape[0]):\n        # get params:\n        x_pos = el_params[i][0]\n        y_pos = el_params[i][1]\n        a     = el_params[i][2]\n        b     = el_params[i][3]\n        phi   = el_params[i][4]\n        value = el_params[i][5]\n\n        # move to pos\n        xc = (xx_base - x_pos)\n        yc = (yy_base - y_pos)\n\n        # rotate\n        xx = xc * np.cos(phi) + yc * np.sin(phi)\n        yy = yc * np.cos(phi) - xc * np.sin(phi)\n\n        # calc squared distance to pos\n        ellipse_points = (xx ** 2) / (a ** 2) + (yy ** 2) / (b ** 2)\n\n        # sum up\n        shepp_logan = shepp_logan + (ellipse_points &lt;= 1) * value\n\n    return np.flip(shepp_logan, axis=0)\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/phantoms/shepp_logan/#pyronn.ct_reconstruction.helpers.phantoms.shepp_logan.shepp_logan_3d","title":"pyronn.ct_reconstruction.helpers.phantoms.shepp_logan.shepp_logan_3d","text":"<pre><code>shepp_logan_3d(shape)\n</code></pre> <pre><code>Creates a Shepp Logan like 3d Phantom. Definition adopted from CONRAD.\n</code></pre> <p>Args:     shape: Shape (in [Y, X]) of Shepp Logan phantom to create.</p> <p>Returns:</p> Type Description <p>Phantom of shape as np.array</p> Source code in <code>pyronn/ct_reconstruction/helpers/phantoms/shepp_logan.py</code> <pre><code>def shepp_logan_3d(shape):\n    \"\"\"\n        Creates a Shepp Logan like 3d Phantom. Definition adopted from CONRAD.\n    Args:\n        shape: Shape (in [Y, X]) of Shepp Logan phantom to create.\n\n    Returns:\n        Phantom of shape as np.array\n    \"\"\"\n    shepp_logan = np.zeros(shape, dtype=np.float32)\n\n    # create meshgrid of coords\n    zz_base, yy_base, xx_base = np.mgrid[:shape[0], :shape[1], :shape[2]]\n\n    # center at 0, 0 and normalize\n    xx_base = (xx_base - (shape[2] - 1) / 2) / ((shape[2] - 1) / 2)\n    yy_base = (yy_base - (shape[1] - 1) / 2) / ((shape[1] - 1) / 2)\n    zz_base = (zz_base - (shape[0] - 1) / 2) / ((shape[0] - 1) / 2)\n\n    # definition of ellipsoids as np.array:\n    #                       delta_x, delta_y, delta_z,        a,       b,       c,            phi,  theta,  psi,     rho\n    el_params = np.array([[       0,       0,       0,     0.69,    0.92,    0.81,              0,      0,    0,     1  ],\n                          [       0, -0.0184,       0,   0.6624,   0.874,    0.78,              0,      0,    0,   -0.8 ],\n                          [    0.22,       0,       0,     0.11,    0.31,    0.22,   -(np.pi)/10.,      0,    0,   -0.2 ],\n                          [   -0.22,       0,       0,     0.16,    0.41,    0.28,    (np.pi)/10.,      0,    0,   -0.2 ],\n                          [       0,    0.35,   -0.15,     0.21,    0.25,    0.41,              0,      0,    0,    0.1 ],\n                          [       0,     0.1,    0.25,    0.046,   0.046,    0.05,              0,      0,    0,    0.1 ],\n                          [       0,    -0.1,    0.25,    0.046,   0.046,    0.05,              0,      0,    0,    0.1 ],\n                          [   -0.08,  -0.605,       0,    0.046,   0.023,    0.05,              0,      0,    0,    0.1 ],\n                          [       0,  -0.605,       0,    0.023,   0.023,    0.02,              0,      0,    0,    0.1 ],\n                          [    0.06,  -0.605,       0,    0.023,   0.046,    0.02,              0,      0,    0,    0.1 ]])\n\n    # create ellipses and sum up\n    for i in range(el_params.shape[0]):\n        # get params:\n        x_pos  = el_params[i][0]\n        y_pos  = el_params[i][1]\n        z_pos  = el_params[i][2]\n        a_axis = el_params[i][3]\n        b_axis = el_params[i][4]\n        c_axis = el_params[i][5]\n        phi    = el_params[i][6]\n        value  = el_params[i][9]\n\n        # move to pos\n        xc = (xx_base - x_pos)\n        yc = (yy_base - y_pos)\n        zc = (zz_base - z_pos)\n\n        # Rotation\n        c = np.cos(phi)\n        s = np.sin(phi)\n        Rz_phi   = np.array([[ c, -s,  0 ],\n                             [ s,  c,  0 ],\n                             [ 0,  0,  1 ]])\n        c = np.cos(0)\n        s = np.sin(0)\n        Ry_theta = np.array([[ c,  0,  s ],\n                             [ 0,  1,  0 ],\n                             [-s,  0,  c ]])\n        c = np.cos(0)\n        s = np.sin(0)\n        Rz_psi   = np.array([[ c, -s,  0 ],\n                             [ s,  c,  0 ],\n                             [ 0,  0,  1 ]])\n\n        # R = Rz(phi) * Ry(theta) * Rz(psi)\n        R = np.dot(np.dot(Rz_phi, Ry_theta), Rz_psi).T\n\n        xx = xc * R[0, 0] + yc * R[0, 1] + zc * R[0, 2]\n        yy = xc * R[1, 0] + yc * R[1, 1] + zc * R[1, 2]\n        zz = xc * R[2, 0] + yc * R[2, 1] + zc * R[2, 2]\n\n        # calc squared distance to pos\n        ellipse_points = (xx ** 2) / (a_axis ** 2) + (yy ** 2) / (b_axis ** 2) + (zz ** 2) / (c_axis ** 2)\n\n        # sum up\n        shepp_logan = shepp_logan + (ellipse_points &lt;= 1) * value\n\n    return shepp_logan\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/trajectories/arbitrary_trajectory/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/trajectories/arbitrary_trajectory.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/trajectories/arbitrary_trajectory/#pyronn.ct_reconstruction.helpers.trajectories.arbitrary_trajectory.arbitrary_projection_matrix","title":"pyronn.ct_reconstruction.helpers.trajectories.arbitrary_trajectory.arbitrary_projection_matrix","text":"<pre><code>arbitrary_projection_matrix(headers, voxel_size=[0.45, 0.45], swap_detector_axis=False, **kwargs)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/trajectories/arbitrary_trajectory.py</code> <pre><code>def arbitrary_projection_matrix(headers,voxel_size = [0.45,0.45], swap_detector_axis=False, **kwargs):\n    #Source: Auto-calibration of cone beam geometries from arbitrary rotating markers using a vector geometry formulation of projection matrices by Graetz, Jonas\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    number_of_projections = len(headers)\n    # init empty\n    projection_matrices = np.zeros((number_of_projections, 3, 4))\n\n    detector_shape = np.array(\n            [headers[0].number_vertical_pixels, headers[0].number_horizontal_pixels])\n\n    # Shift into left upper corner of the detector\n    detector_left_corner_trans = np.eye(3) \n    detector_left_corner_trans[0, 2] = + (float(headers[0].number_vertical_pixels) - 1.) / 2.\n    detector_left_corner_trans[1, 2] = + (float( headers[0].number_horizontal_pixels) - 1.) / 2.\n    detector_left_corner_trans[0, 0] *= 1\n    detector_left_corner_trans[1, 1] *= -1\n    detector_left_corner_trans[2, 2] = 1.\n    traj_type = 'circ' if np.array_equal(np.array(headers[0].agv_source_position),np.array([0,0,0])) else 'free'\n    print(traj_type)\n    #Initial stuff for circular trajectory:\n    if traj_type == 'circ':\n        init_source_position = [0, 0, headers[0].focus_object_distance_in_mm]\n        init_detector_position = [0, 0, headers[0].focus_object_distance_in_mm - headers[0].focus_detector_distance_in_mm]\n        init_detector_line_direction = [0,1,0]\n        init_detector_column_direction = [1,0,0]\n        angular_range = headers[0].scan_range_in_rad\n        if angular_range == 0:\n            angular_range = 2 * np.pi\n        current_angle = 0 \n        angular_increment = angular_range/number_of_projections\n\n    for p, header in enumerate(headers): \n        if traj_type == 'free':\n            det_h = np.array(header.agv_detector_line_direction)\n            det_v = -1* np.array(header.agv_detector_col_direction)\n            source_center_in_voxel = (np.array(header.agv_source_position)/1000)/voxel_size[0] # in mm\n            detector_center_in_voxel  = (np.array(header.agv_detector_center_position)/1000)/voxel_size[0] # in mm\n        else:\n            # rotation about x axis =&gt; Column direction of the detector\n            R_x_axis = np.eye(3, 3)\n            R_x_axis = np.array([1, 0, 0,\n                                           0, np.cos(-current_angle), -np.sin(-current_angle),\n                                           0, np.sin(-current_angle), np.cos(-current_angle)]).reshape((3, 3))\n            source_center_in_voxel = np.dot(R_x_axis,init_source_position)/voxel_size[0]\n            detector_center_in_voxel = np.dot(R_x_axis,init_detector_position)/voxel_size[0]\n            det_h = np.dot(R_x_axis,init_detector_line_direction)\n            det_v = np.dot(R_x_axis,init_detector_column_direction)\n            current_angle += angular_increment\n\n        #[H|V|d-s]\n        h_v_sdd = np.column_stack((det_h, det_v, (detector_center_in_voxel - source_center_in_voxel) ))\n        h_v_sdd_invers = np.linalg.inv(h_v_sdd)\n        # [H|V|d-s]^-1 * -s\n        back_part = h_v_sdd_invers @ (-source_center_in_voxel)\n        proj_matrix = np.column_stack((h_v_sdd_invers,back_part))\n        projection_matrices[p] =  detector_left_corner_trans @ proj_matrix\n\n        # post processing to get the same oriented outputvolume like ezrt commandline reco: =&gt; tested, no changes needed to get the same orientation as Firefly ART\n        # flip Z-Axis: Z = -Z\n        if swap_detector_axis:\n            projection_matrices[p][0:3, 2] = projection_matrices[p][0:3, 2] * -1.0\n\n        # change orientation of current matrix from XYZ to YXZ: exchange the first two columns\n        # projection_matrices[p][0:3, 0:2] = np.flip(projection_matrices[p][0:3, 0:2], axis=1)\n        # change orientation of current matrix from YXZ to YZX: exchange the last two columns\n        # projection_matrices[p][0:3, 1:3] = np.flip(projection_matrices[p][0:3, 1:3], axis=1)\n    return projection_matrices\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/trajectories/arbitrary_trajectory/#pyronn.ct_reconstruction.helpers.trajectories.arbitrary_trajectory.fibonacci_sphere_projecton_matrix","title":"pyronn.ct_reconstruction.helpers.trajectories.arbitrary_trajectory.fibonacci_sphere_projecton_matrix","text":"<pre><code>fibonacci_sphere_projecton_matrix(number_of_projections, source_detector_distance, detector_spacing, source_isocenter_distance, detector_origin, swap_axis=False, *args, **kwargs)\n</code></pre> Source code in <code>pyronn/ct_reconstruction/helpers/trajectories/arbitrary_trajectory.py</code> <pre><code>def fibonacci_sphere_projecton_matrix(number_of_projections, source_detector_distance,\n                                      detector_spacing, source_isocenter_distance, detector_origin,\n                                      swap_axis=False, *args, **kwargs):\n    # init empty\n    # assert len(pts) == number_of_projections\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    pts = fibonacci_sphere(number_of_projections)\n    projection_matrices = np.zeros((len(pts), 3, 4))\n    x_axis = np.array([1., 0., 0.])\n    y_axis = np.array([0., 1., 0.])\n    z_axis = np.array([0., 0., 1.])\n\n    u_dir = y_axis\n    if swap_axis:\n        v_dir = x_axis\n    else:\n        v_dir = -x_axis\n\n    intrinsic_params_mat = np.eye(3, 3)\n    for i in range(2):\n        intrinsic_params_mat[i, i] = source_detector_distance / detector_spacing[1 - i]\n\n    # calc and set detector origin\n    # we need t_x and t_y, and follow the [z,y,x] convention\n\n    intrinsic_params_mat[0, 2] = detector_origin[-1] / detector_spacing[-1] * -1\n    intrinsic_params_mat[1, 2] = detector_origin[-2] / detector_spacing[-2] * -1\n\n    for p in range(len(pts)):\n        extrinsic_params_mat = np.eye(4, 4)\n\n        R_to_plane = np.eye(4, 4)\n        R_to_plane[0:3, 0:3] = np.array([z_axis, np.cross(z_axis, x_axis), -x_axis])\n\n\n        axis_align_R = np.eye(4, 4)\n        axis_align_R[0:3, 0] = u_dir\n        axis_align_R[0:3, 1] = v_dir\n        axis_align_R[0:3, 2] = np.cross(u_dir, v_dir)\n        axis_align_R = axis_align_R.T\n\n        translation = np.eye(4, 4)\n        translation[0:4, 3] = np.array([0, 0, source_isocenter_distance, 1])\n\n        R_to_pts = np.eye(4, 4)\n        R_to_pts[0:3, 0:3] = rotation_matrix_from_points(pts[p],\n                                                         np.array([0, 0, source_isocenter_distance])\n                                                         )\n\n        extrinsic_params_mat = np.dot(np.dot(np.dot(translation, axis_align_R), R_to_pts), R_to_plane)\n        extrinsic_params_mat = extrinsic_params_mat / extrinsic_params_mat[3, 3]\n\n        projection_matrices[p][0:3, 0:3] = np.dot(intrinsic_params_mat, extrinsic_params_mat[0:3, 0:3])\n        projection_matrices[p][0:3, 3] = np.dot(intrinsic_params_mat, extrinsic_params_mat[0:3, 3])\n\n    return projection_matrices\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/trajectories/circular_trajectory/","title":"Reference for <code>pyronn/ct_reconstruction/helpers/trajectories/circular_trajectory.py</code>","text":""},{"location":"reference/ct_reconstruction/helpers/trajectories/circular_trajectory/#pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory.circular_trajectory_2d","title":"pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory.circular_trajectory_2d","text":"<pre><code>circular_trajectory_2d(number_of_projections, angular_range, swap_detector_axis)\n</code></pre> <pre><code>Generates the central ray vectors defining a circular trajectory for use with the 2d projection layers.\n</code></pre> <p>Args:     geometry: 2d Geometry class including angular_range and number_of_projections Returns:     Central ray vectors as np.array.</p> Source code in <code>pyronn/ct_reconstruction/helpers/trajectories/circular_trajectory.py</code> <pre><code>def circular_trajectory_2d(number_of_projections, angular_range, swap_detector_axis):\n    \"\"\"\n        Generates the central ray vectors defining a circular trajectory for use with the 2d projection layers.\n    Args:\n        geometry: 2d Geometry class including angular_range and number_of_projections\n    Returns:\n        Central ray vectors as np.array.\n    \"\"\"\n    rays = np.zeros([number_of_projections, 2])\n    angular_increment = (angular_range[1] - angular_range[0]) / number_of_projections\n    for i in range(number_of_projections):\n        if swap_detector_axis:\n            rays[i] = [np.cos(angular_range[0] + i * angular_increment), -np.sin(angular_range[0] + i * angular_increment)]\n        else:\n            rays[i] = [np.cos(angular_range[0] + i * angular_increment), np.sin(angular_range[0] + i * angular_increment)]\n    return rays\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/trajectories/circular_trajectory/#pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory.circular_trajectory_3d","title":"pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory.circular_trajectory_3d","text":"<pre><code>circular_trajectory_3d(number_of_projections, angular_range, detector_spacing, detector_origin, source_isocenter_distance, source_detector_distance, swap_detector_axis, **kwargs)\n</code></pre> <pre><code>Generates the projection matrices defining a circular trajectory around the z-axis\nfor use with the 3d projection layers.\nAdapted from CONRAD Source code https://github.com/akmaier/CONRAD.\n</code></pre> <p>Args:     geometry: 3d Geometry class including angular_range, number_of_projections, source_detector_distance,     detector_spacing, volume_origin, volume_shape and volume_spacing. Returns:     Projection matrices with shape (num_projections, 3, 4) as np.array.</p> Source code in <code>pyronn/ct_reconstruction/helpers/trajectories/circular_trajectory.py</code> <pre><code>def circular_trajectory_3d(number_of_projections, angular_range, detector_spacing, detector_origin, source_isocenter_distance, source_detector_distance, swap_detector_axis, **kwargs):\n    \"\"\"\n        Generates the projection matrices defining a circular trajectory around the z-axis\n        for use with the 3d projection layers.\n        Adapted from CONRAD Source code https://github.com/akmaier/CONRAD.\n    Args:\n        geometry: 3d Geometry class including angular_range, number_of_projections, source_detector_distance,\n        detector_spacing, volume_origin, volume_shape and volume_spacing.\n    Returns:\n        Projection matrices with shape (num_projections, 3, 4) as np.array.\n    \"\"\"\n\n    # init empty\n    projection_matrices = np.zeros((number_of_projections, 3, 4))\n\n    # axes for later use\n    x_axis = np.array([1.0, 0.0, 0.0])\n    y_axis = np.array([0.0, 1.0, 0.0])\n    z_axis = np.array([0.0, 0.0, 1.0])\n\n    # defining u and v directions by: main coord axes\n    u_dir = y_axis\n    if swap_detector_axis:\n        v_dir = x_axis\n    else:\n        v_dir = -x_axis\n\n    # configure intrinsic camera parameters\n    intrinsic_params_mat = np.eye(3, 3)\n    for i in range(2):\n        intrinsic_params_mat[i, i] = source_detector_distance / detector_spacing[1-i]\n\n    # calc and set detector origin\n    # we need t_x and t_y, and follow the [z,y,x] convention\n\n    intrinsic_params_mat[0,2] = detector_origin[-1] / detector_spacing[-1] *-1\n    intrinsic_params_mat[1,2] = detector_origin[-2] / detector_spacing[-2] *-1\n    # intrinsic_params_mat[0:2, 2] = detector_origin / detector_spacing *-1\n    # configure extrinisc pararams and create projection_matrices\n    current_angle = angular_range[0]\n    angular_increment = (angular_range[1] - angular_range[0]) / number_of_projections\n    for p in range(number_of_projections):\n        # calculate extrinsic params\n        extrinsic_params_mat = np.eye(4, 4)\n\n        # rotation of axes from world system to plane of rotation system\n        R_to_plane = np.eye(4, 4)\n        R_to_plane[0:3, 0:3] = np.array([z_axis, np.cross(z_axis, x_axis), -x_axis])\n\n        # rotation for u and v direction\n        axis_align_R = np.eye(4, 4)\n        # v_dir = z_axis\n        axis_align_R[0:3, 0] = u_dir\n        axis_align_R[0:3, 1] = v_dir\n        axis_align_R[0:3, 2] = np.cross(u_dir, v_dir)\n        axis_align_R = axis_align_R.T\n\n        # rotation about x axis\n        R_x_axis = np.eye(4, 4)\n        R_x_axis[0:3, 0:3] = np.array([1, 0, 0,\n                                       0, np.cos(-current_angle), -np.sin(-current_angle),\n                                       0, np.sin(-current_angle), np.cos(-current_angle)]).reshape((3, 3))\n\n        # R_x_axis = np.eye(4, 4)\n        # R_x_axis[0:3, 0:3] = np.array([\n        #                                np.cos(-current_angle), -np.sin(-current_angle),0,\n        #                                np.sin(-current_angle), np.cos(-current_angle), 0,\n        #                                 0, 0, 1]).reshape((3, 3))\n\n        # translation of camera\n        translation = np.eye(4, 4)\n        translation[0:4, 3] = np.array([0, 0, -source_isocenter_distance, 1])\n\n        # combine the above into 4x4 extrinsic params matrix\n        extrinsic_params_mat = np.dot(np.dot(np.dot(axis_align_R, translation), R_x_axis), R_to_plane.T)\n        extrinsic_params_mat = extrinsic_params_mat / extrinsic_params_mat[3, 3]\n\n        # calculate projection matrix\n        projection_matrices[p][0:3, 0:3] = np.dot(intrinsic_params_mat, extrinsic_params_mat[0:3, 0:3])\n        projection_matrices[p][0:3, 3] = np.dot(intrinsic_params_mat, extrinsic_params_mat[0:3, 3])\n\n        # next angle\n        current_angle += angular_increment\n\n    return projection_matrices\n</code></pre>"},{"location":"reference/ct_reconstruction/helpers/trajectories/circular_trajectory/#pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory.multi_circular_trajectory_3d","title":"pyronn.ct_reconstruction.helpers.trajectories.circular_trajectory.multi_circular_trajectory_3d","text":"<pre><code>multi_circular_trajectory_3d(number_of_projections, longtitude, angular_range, detector_spacing, detector_origin, source_isocenter_distance, source_detector_distance, swap_detector_axis, **kwargs)\n</code></pre> <pre><code>Generates the projection matrices defining a circular trajectory around the z-axis\nfor use with the 3d projection layers.\nAdapted from CONRAD Source code https://github.com/akmaier/CONRAD.\n</code></pre> <p>Args:     geometry: 3d Geometry class including angular_range, number_of_projections, source_detector_distance,     detector_spacing, volume_origin, volume_shape and volume_spacing. Returns:     Projection matrices with shape (num_projections, 3, 4) as np.array.</p> Source code in <code>pyronn/ct_reconstruction/helpers/trajectories/circular_trajectory.py</code> <pre><code>def multi_circular_trajectory_3d(number_of_projections, longtitude, angular_range, detector_spacing, detector_origin, source_isocenter_distance, source_detector_distance, swap_detector_axis, **kwargs):\n    \"\"\"\n        Generates the projection matrices defining a circular trajectory around the z-axis\n        for use with the 3d projection layers.\n        Adapted from CONRAD Source code https://github.com/akmaier/CONRAD.\n    Args:\n        geometry: 3d Geometry class including angular_range, number_of_projections, source_detector_distance,\n        detector_spacing, volume_origin, volume_shape and volume_spacing.\n    Returns:\n        Projection matrices with shape (num_projections, 3, 4) as np.array.\n    \"\"\"\n\n    # init empty\n    projection_matrices = np.zeros((number_of_projections, 3, 4))\n\n    # axes for later use\n    x_axis = np.array([1.0, 0.0, 0.0])\n    y_axis = np.array([0.0, 1.0, 0.0])\n    z_axis = np.array([0.0, 0.0, 1.0])\n\n    # defining u and v directions by: main coord axes\n    u_dir = y_axis\n    if swap_detector_axis:\n        v_dir = x_axis\n    else:\n        v_dir = -x_axis\n\n    # configure intrinsic camera parameters\n    intrinsic_params_mat = np.eye(3, 3)\n    for i in range(2):\n        intrinsic_params_mat[i, i] = source_detector_distance / detector_spacing[1-i]\n\n    # calc and set detector origin\n    # we need t_x and t_y, and follow the [z,y,x] convention\n\n    intrinsic_params_mat[0,2] = detector_origin[-1] / detector_spacing[-1] *-1\n    intrinsic_params_mat[1,2] = detector_origin[-2] / detector_spacing[-2] *-1\n    # intrinsic_params_mat[0:2, 2] = detector_origin / detector_spacing *-1\n    # configure extrinisc pararams and create projection_matrices\n    current_angle = angular_range[0]\n    angular_increment = (angular_range[1] - angular_range[0]) / number_of_projections\n    for p in range(number_of_projections):\n        # calculate extrinsic params\n        extrinsic_params_mat = np.eye(4, 4)\n\n        # # rotation of axes from world system to plane of rotation system\n        R_to_plane = np.eye(4, 4)\n        R_to_plane[0:3, 0:3] = np.array([z_axis, np.cross(z_axis, x_axis), -x_axis])\n\n        # rotation for u and v direction\n        axis_align_R = np.eye(4, 4)\n        axis_align_R[0:3, 0] = u_dir\n        axis_align_R[0:3, 1] = v_dir\n        axis_align_R[0:3, 2] = np.cross(u_dir, v_dir)\n        axis_align_R = axis_align_R.T\n\n        # rotation about x axis\n        R_x_axis = np.eye(4, 4)\n        R_x_axis[0:3, 0:3] = np.array([1, 0, 0,\n                                       0, np.cos(-current_angle), -np.sin(-current_angle),\n                                       0, np.sin(-current_angle), np.cos(-current_angle)]).reshape((3, 3))\n\n        # rotation about z axis\n        R_z_axis = np.eye(4, 4)\n        R_z_axis[0:3, 0:3] = np.array([\n                                       np.cos(-longtitude), -np.sin(-longtitude),0,\n                                       np.sin(-longtitude), np.cos(-longtitude), 0,\n                                        0, 0, 1]).reshape((3, 3))\n\n        # translation of camera\n        translation = np.eye(4, 4)\n        translation[0:4, 3] = np.array([0, 0, -source_isocenter_distance, 1])\n\n        # combine the above into 4x4 extrinsic params matrix\n        extrinsic_params_mat = np.dot(np.dot(np.dot(np.dot(axis_align_R, translation), R_x_axis), R_z_axis), R_to_plane.T)\n        extrinsic_params_mat = extrinsic_params_mat / extrinsic_params_mat[3, 3]\n\n        # calculate projection matrix\n        projection_matrices[p][0:3, 0:3] = np.dot(intrinsic_params_mat, extrinsic_params_mat[0:3, 0:3])\n        projection_matrices[p][0:3, 3] = np.dot(intrinsic_params_mat, extrinsic_params_mat[0:3, 3])\n\n        # next angle\n        current_angle += angular_increment\n\n    return projection_matrices\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/backprojection_2d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/backprojection_2d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/backprojection_2d/#pyronn.ct_reconstruction.layers.backprojection_2d.ParallelBackProjectionFor2D","title":"pyronn.ct_reconstruction.layers.backprojection_2d.ParallelBackProjectionFor2D","text":""},{"location":"reference/ct_reconstruction/layers/backprojection_2d/#pyronn.ct_reconstruction.layers.backprojection_2d.ParallelBackProjectionFor2D.forward","title":"forward","text":"<pre><code>forward(input, geometry, for_train=False, debug=False)\n</code></pre> <p>Reconstruction for the 2D parallel beam CT.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <p>(1, number_of_projections, detection_size) numpy array or torch.Tensor.</p> required <code>geometry</code> <p>The projection geometry used for projection.</p> required <code>for_train</code> <p>Set the return value data type if the backend is torch. You can get a numpy.array by setting this</p> <code>False</code> return <p>The reconstruction result of 2D parallel beam CT.</p> Source code in <code>pyronn/ct_reconstruction/layers/backprojection_2d.py</code> <pre><code>def forward(self, input, geometry, for_train=False, debug=False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Reconstruction for the 2D parallel beam CT.\n\n    args:\n        input: (1, number_of_projections, detection_size) numpy array or torch.Tensor.\n        geometry: The projection geometry used for projection.\n        for_train: Set the return value data type if the backend is torch. You can get a numpy.array by setting this\n        value False, otherwise you will get a torch.Tensor.\n\n    return:\n        The reconstruction result of 2D parallel beam CT.\n    '''\n    try:\n        import torch\n        from pyronn.ct_reconstruction.layers.torch.backprojection_2d import ParallelBackProjection2D\n\n        if not isinstance(input, torch.Tensor):\n            sinogram = torch.tensor(input.copy(), dtype=torch.float32)\n        else:\n            sinogram = torch.clone(input)\n\n        tensor_geometry = {}\n        geo_dict = vars(geometry)\n        for k in geo_dict:\n            param = geo_dict[k]\n            try:\n                if hasattr(param, '__len__'):\n                    tmp_tensor = torch.Tensor(param)\n\n                    sinogram = sinogram.cuda()\n                    tensor_geometry[k] = tmp_tensor.cuda()\n            except Exception as e:\n                if isinstance(e, TypeError):\n                    if debug: print('Attribute &lt;' + k + '&gt; could not be transformed to torch.Tensor')\n                else:\n                    raise e\n\n        reco = ParallelBackProjection2D().forward(sinogram.contiguous(), **tensor_geometry)\n        if for_train:\n            return reco\n\n        if reco.device.type == 'cuda':\n            return reco.detach().cpu().numpy()\n        return reco.cpu().numpy()\n\n    except Exception as e:\n        if isinstance(e, ModuleNotFoundError):\n            from pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d import parallel_backprojection2d\n            return parallel_backprojection2d(input, geometry)\n        else:\n            raise e\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/backprojection_2d/#pyronn.ct_reconstruction.layers.backprojection_2d.FanBackProjectionFor2D","title":"pyronn.ct_reconstruction.layers.backprojection_2d.FanBackProjectionFor2D","text":""},{"location":"reference/ct_reconstruction/layers/backprojection_2d/#pyronn.ct_reconstruction.layers.backprojection_2d.FanBackProjectionFor2D.forward","title":"forward","text":"<pre><code>forward(input, geometry, for_train=False, debug=False)\n</code></pre> <p>Reconstruction for the 2D fan beam CT.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <p>(1, number_of_projections, detection_size) numpy array or torch.Tensor.</p> required <code>geometry</code> <p>The projection geometry used for projection.</p> required <code>for_train</code> <p>Set the return value data type if the backend is torch. You can get a numpy.array by setting this</p> <code>False</code> return <p>The reconstruction result of 2D fan beam CT.</p> Source code in <code>pyronn/ct_reconstruction/layers/backprojection_2d.py</code> <pre><code>def forward(self, input, geometry, for_train=False, debug=False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Reconstruction for the 2D fan beam CT.\n\n    args:\n        input: (1, number_of_projections, detection_size) numpy array or torch.Tensor.\n        geometry: The projection geometry used for projection.\n        for_train: Set the return value data type if the backend is torch. You can get a numpy.array by setting this\n        value False, otherwise you will get a torch.Tensor.\n\n    return:\n        The reconstruction result of 2D fan beam CT.\n    '''\n    try:\n        import torch\n        from pyronn.ct_reconstruction.layers.torch.backprojection_2d import FanBackProjection2D\n\n        if not isinstance(input, torch.Tensor):\n            sinogram = torch.tensor(input.copy(), dtype=torch.float32).cuda()\n        else:\n            sinogram = torch.clone(input).cuda()\n\n        tensor_geometry = {}\n        geo_dict = vars(geometry)\n        for k in geo_dict:\n            param = geo_dict[k]\n            try:\n                if hasattr(param, '__len__'):\n                    tmp_tensor = torch.Tensor(param)\n                else:\n                    tmp_tensor = torch.Tensor([param])\n\n                tensor_geometry[k] = tmp_tensor.cuda()\n            except Exception as e:\n                if isinstance(e, TypeError):\n                    if debug: print('Attribute &lt;' + k + '&gt; could not be transformed to torch.Tensor')\n                else:\n                    raise e\n        reco = FanBackProjection2D().forward(sinogram.contiguous(), **tensor_geometry)\n        if for_train:\n            return reco\n\n        if reco.device.type == 'cuda':\n            return reco.detach().cpu().numpy()\n        return reco.cpu().numpy()\n\n    except Exception as e:\n        if isinstance(e, ModuleNotFoundError):\n            from pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d import fan_backprojection2d\n            return fan_backprojection2d(input, geometry)\n        else:\n            raise e\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/backprojection_3d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/backprojection_3d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/backprojection_3d/#pyronn.ct_reconstruction.layers.backprojection_3d.ConeBackProjectionFor3D","title":"pyronn.ct_reconstruction.layers.backprojection_3d.ConeBackProjectionFor3D","text":""},{"location":"reference/ct_reconstruction/layers/backprojection_3d/#pyronn.ct_reconstruction.layers.backprojection_3d.ConeBackProjectionFor3D.forward","title":"forward","text":"<pre><code>forward(input, geometry, for_train=False, debug=False)\n</code></pre> <p>Reconstruction for the 3D cone beam CT.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <p>(1, number_of_projections, detector_height, detector_width) numpy array or torch.Tensor.</p> required <code>geometry</code> <p>The projection geometry used for projection.</p> required <code>for_train</code> <p>Set the return value data type if the backend is torch. You can get a numpy.array by setting this</p> <code>False</code> return <p>The reconstruction result of 2D parallel beam CT.</p> Source code in <code>pyronn/ct_reconstruction/layers/backprojection_3d.py</code> <pre><code>def forward(self, input, geometry, for_train=False, debug=False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Reconstruction for the 3D cone beam CT.\n\n    args:\n        input: (1, number_of_projections, detector_height, detector_width) numpy array or torch.Tensor.\n        geometry: The projection geometry used for projection.\n        for_train: Set the return value data type if the backend is torch. You can get a numpy.array by setting this\n        value False, otherwise you will get a torch.Tensor.\n\n    return:\n        The reconstruction result of 2D parallel beam CT.\n    '''\n    try:\n        import torch\n        from pyronn.ct_reconstruction.layers.torch.backprojection_3d import ConeBackProjection3D\n\n        if not isinstance(input, torch.Tensor):\n            sinogram = torch.tensor(input.copy(), dtype=torch.float32).cuda()\n        else:\n            sinogram = torch.clone(input).cuda()\n\n        tensor_geometry = {}\n        geo_dict = vars(geometry)\n        for k in geo_dict:\n            param = geo_dict[k]\n            try:\n                if hasattr(param, '__len__'):\n                    tmp_tensor = torch.Tensor(param)\n                else:\n                    tmp_tensor = torch.Tensor([param])\n\n                tensor_geometry[k] = tmp_tensor.cuda()\n            except Exception as e:\n                if isinstance(e, TypeError):\n                    if debug: print('Attribute &lt;' + k + '&gt; could not be transformed to torch.Tensor')\n                else:\n                    raise e\n\n        reco = ConeBackProjection3D().forward(sinogram.contiguous(), **tensor_geometry)\n        if for_train:\n            return reco\n\n        if reco.device.type == 'cuda':\n            return reco.detach().cpu().numpy()\n        return reco.cpu().numpy()\n\n    except Exception as e:\n        if isinstance(e, ModuleNotFoundError):\n            from pyronn.ct_reconstruction.layers.tensorflow.backprojection_3d import cone_backprojection3d\n            return cone_backprojection3d(input, geometry)\n        else:\n            raise e\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/projection_2d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/projection_2d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/projection_2d/#pyronn.ct_reconstruction.layers.projection_2d.ParallelProjectionFor2D","title":"pyronn.ct_reconstruction.layers.projection_2d.ParallelProjectionFor2D","text":""},{"location":"reference/ct_reconstruction/layers/projection_2d/#pyronn.ct_reconstruction.layers.projection_2d.ParallelProjectionFor2D.forward","title":"forward","text":"<pre><code>forward(input, geometry, for_train=False, debug=False)\n</code></pre> <p>Projection for the 2D parallel beam CT.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <p>(1, number_of_projections, detection_size) numpy array or torch.Tensor.</p> required <code>geometry</code> <p>The projection geometry used for projection.</p> required <code>for_train</code> <p>Set the return value data type if the backend is torch. You can get a numpy.array by setting this</p> <code>False</code> return <p>The reconstruction result of 2D parallel beam CT.</p> Source code in <code>pyronn/ct_reconstruction/layers/projection_2d.py</code> <pre><code>def forward(self, input, geometry, for_train=False, debug=False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Projection for the 2D parallel beam CT.\n\n    args:\n        input: (1, number_of_projections, detection_size) numpy array or torch.Tensor.\n        geometry: The projection geometry used for projection.\n        for_train: Set the return value data type if the backend is torch. You can get a numpy.array by setting this\n        value False, otherwise you will get a torch.Tensor.\n\n    return:\n        The reconstruction result of 2D parallel beam CT.\n    '''\n\n    try:\n        import torch\n        from pyronn.ct_reconstruction.layers.torch.projection_2d import ParallelProjection2D\n\n        if not isinstance(input, torch.Tensor):\n            phantom = torch.tensor(input.copy(), dtype=torch.float32)\n        else:\n            phantom = torch.clone(input).cuda()\n\n        tensor_geometry = {}\n        geo_dict = vars(geometry)\n        for k in geo_dict:\n            param = geo_dict[k]\n            try:\n                if hasattr(param, '__len__'):\n                    tmp_tensor = torch.Tensor(param)\n                else:\n                    tmp_tensor = torch.Tensor([param])\n\n                tensor_geometry[k] = tmp_tensor.cuda()\n            except Exception as e:\n                if isinstance(e, TypeError):\n                    if debug: print('Attribute &lt;' + k + '&gt; could not be transformed to torch.Tensor')\n                else:\n                    raise e\n        sinogram =  ParallelProjection2D().forward(phantom, **tensor_geometry)\n        if for_train:\n            return sinogram\n\n        if sinogram.device.type == 'cuda':\n            return sinogram.detach().cpu().numpy()\n        return sinogram.cpu().numpy()\n\n    except Exception as e:\n        if isinstance(e, ModuleNotFoundError):\n            from pyronn.ct_reconstruction.layers.tensorflow.projection_2d import parallel_projection2d\n            return parallel_projection2d(input, geometry)\n        else:\n            raise e\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/projection_2d/#pyronn.ct_reconstruction.layers.projection_2d.FanProjectionFor2D","title":"pyronn.ct_reconstruction.layers.projection_2d.FanProjectionFor2D","text":""},{"location":"reference/ct_reconstruction/layers/projection_2d/#pyronn.ct_reconstruction.layers.projection_2d.FanProjectionFor2D.forward","title":"forward","text":"<pre><code>forward(input, geometry, for_train=False, debug=False)\n</code></pre> <p>Projection for the 2D fan beam CT.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <p>(1, number_of_projections, detection_size) numpy array or torch.Tensor.</p> required <code>geometry</code> <p>The projection geometry used for projection.</p> required <code>for_train</code> <p>Set the return value data type if the backend is torch. You can get a numpy.array by setting this</p> <code>False</code> return <p>The reconstruction result of 2D fan beam CT.</p> Source code in <code>pyronn/ct_reconstruction/layers/projection_2d.py</code> <pre><code>def forward(self, input, geometry, for_train=False, debug=False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Projection for the 2D fan beam CT.\n\n    args:\n        input: (1, number_of_projections, detection_size) numpy array or torch.Tensor.\n        geometry: The projection geometry used for projection.\n        for_train: Set the return value data type if the backend is torch. You can get a numpy.array by setting this\n        value False, otherwise you will get a torch.Tensor.\n\n    return:\n        The reconstruction result of 2D fan beam CT.\n    '''\n    try:\n        import torch\n        from pyronn.ct_reconstruction.layers.torch.projection_2d import FanProjection2D\n\n        if not isinstance(input, torch.Tensor):\n            phantom = torch.tensor(input.copy(), dtype=torch.float32).cuda()\n        else:\n            phantom = torch.clone(input).cuda()\n\n        tensor_geometry = {}\n        geo_dict = vars(geometry)\n        for k in geo_dict:\n            param = geo_dict[k]\n            try:\n                if hasattr(param, '__len__'):\n                    tmp_tensor = torch.Tensor(param)\n                else:\n                    tmp_tensor = torch.Tensor([param])\n\n                tensor_geometry[k] = tmp_tensor.cuda()\n            except Exception as e:\n                if isinstance(e, TypeError):\n                    if debug: print('Attribute &lt;' + k + '&gt; could not be transformed to torch.Tensor')\n                else:\n                    raise e\n\n        sinogram = FanProjection2D().forward(phantom, **tensor_geometry)\n        if for_train:\n            return sinogram\n\n        if sinogram.device.type == 'cuda':\n            return sinogram.detach().cpu().numpy()\n        return sinogram.cpu().numpy()\n\n    except Exception as e:\n        if isinstance(e, ModuleNotFoundError):\n            from pyronn.ct_reconstruction.layers.tensorflow.projection_2d import fan_projection2d\n            return fan_projection2d(input, geometry)\n        else: raise e\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/projection_3d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/projection_3d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/projection_3d/#pyronn.ct_reconstruction.layers.projection_3d.Projection3D","title":"pyronn.ct_reconstruction.layers.projection_3d.Projection3D","text":"<pre><code>Projection3D()\n</code></pre> Source code in <code>pyronn/ct_reconstruction/layers/projection_3d.py</code> <pre><code>def __init__(self):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    self.backend = pyronn.read_backend()\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/projection_3d/#pyronn.ct_reconstruction.layers.projection_3d.ConeProjectionFor3D","title":"pyronn.ct_reconstruction.layers.projection_3d.ConeProjectionFor3D","text":"<pre><code>ConeProjectionFor3D()\n</code></pre> <p>               Bases: <code>Projection3D</code></p> Source code in <code>pyronn/ct_reconstruction/layers/projection_3d.py</code> <pre><code>def __init__(self):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    self.backend = pyronn.read_backend()\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/projection_3d/#pyronn.ct_reconstruction.layers.projection_3d.ConeProjectionFor3D.forward","title":"forward","text":"<pre><code>forward(input, geometry, for_train=False, debug=False)\n</code></pre> <p>Projection for the 3D cone beam CT.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <p>(1, number_of_projections, detection_size) numpy array or torch.Tensor.</p> required <code>geometry</code> <p>The projection geometry used for projection.</p> required <code>for_train</code> <p>Set the return value data type if the backend is torch. You can get a numpy.array by setting this</p> <code>False</code> return <p>The reconstruction result of 3D cone beam CT.</p> Source code in <code>pyronn/ct_reconstruction/layers/projection_3d.py</code> <pre><code>def forward(self, input, geometry, for_train=False, debug=False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Projection for the 3D cone beam CT.\n\n    args:\n        input: (1, number_of_projections, detection_size) numpy array or torch.Tensor.\n        geometry: The projection geometry used for projection.\n        for_train: Set the return value data type if the backend is torch. You can get a numpy.array by setting this\n        value False, otherwise you will get a torch.Tensor.\n\n    return:\n        The reconstruction result of 3D cone beam CT.\n    '''\n    try:\n        import torch\n        from pyronn.ct_reconstruction.layers.torch.projection_3d import ConeProjection3D\n\n        if not isinstance(input, torch.Tensor):\n            phantom = torch.tensor(input.copy(), dtype=torch.float32).cuda()\n        else:\n            phantom = torch.clone(input).cuda()\n\n        tensor_geometry = {}\n        geo_dict = vars(geometry)\n        for k in geo_dict:\n            param = geo_dict[k]\n            try:\n                if hasattr(param, '__len__'):\n                    tmp_tensor = torch.Tensor(param)\n                else:\n                    tmp_tensor = torch.Tensor([param])\n\n\n                tensor_geometry[k] = tmp_tensor.cuda()\n            except Exception as e:\n                if isinstance(e, TypeError):\n                    if debug: print('Attribute &lt;' + k + '&gt; could not be transformed to torch.Tensor')\n                else:\n                    raise e\n\n        sinogram = ConeProjection3D().forward(phantom, **tensor_geometry)\n        if for_train:\n            return sinogram\n\n        if sinogram.device.type == 'cuda':\n            return sinogram.detach().cpu().numpy()\n        return sinogram.cpu().numpy()\n\n    except Exception as e:\n        if isinstance(e, ModuleNotFoundError):\n            from pyronn.ct_reconstruction.layers.tensorflow.projection_3d import cone_projection3d\n            return cone_projection3d(input, geometry)\n        else:\n            raise e\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_2d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_2d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_2d/#pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d.parallel_backprojection2d","title":"pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d.parallel_backprojection2d","text":"<pre><code>parallel_backprojection2d(sinogram, geometry)\n</code></pre> <p>Wrapper function for making the layer call. Args:     volume:     Input volume to project.     geometry:   Corresponding GeometryParallel2D Object defining parameters. Returns:         Initialized lme_custom_ops.parallel_backprojection2d layer.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_2d.py</code> <pre><code>def parallel_backprojection2d(sinogram, geometry):\n    \"\"\"\n    Wrapper function for making the layer call.\n    Args:\n        volume:     Input volume to project.\n        geometry:   Corresponding GeometryParallel2D Object defining parameters.\n    Returns:\n            Initialized lme_custom_ops.parallel_backprojection2d layer.\n    \"\"\"\n    batch = np.shape(sinogram)[0]\n    return pyronn_layers.parallel_backprojection2d(sinogram,\n                                                   volume_shape=geometry.volume_shape,\n                                                    volume_origin   =np.broadcast_to(geometry.volume_origin,[batch,*np.shape(geometry.volume_origin)]),\n                                                    detector_origin =np.broadcast_to(geometry.detector_origin,[batch,*np.shape(geometry.detector_origin)]),\n                                                    volume_spacing  =np.broadcast_to(geometry.volume_spacing,[batch,*np.shape(geometry.volume_spacing)]),\n                                                    detector_spacing=np.broadcast_to(geometry.detector_spacing,[batch,*np.shape(geometry.detector_spacing)]),\n                                                    ray_vectors     =np.broadcast_to(geometry.trajectory,[batch,*np.shape(geometry.trajectory)]))\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_2d/#pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d._backproject_grad","title":"pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d._backproject_grad","text":"<pre><code>_backproject_grad(op, grad)\n</code></pre> <p>Compute the gradient of the backprojector op by invoking the forward projector.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_2d.py</code> <pre><code>@ops.RegisterGradient(\"FanBackprojection2D\")\ndef _backproject_grad(op, grad):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n        Compute the gradient of the backprojector op by invoking the forward projector.\n    '''\n    proj = pyronn_layers.fan_projection2d(\n        volume=grad,\n        projection_shape=op.inputs[0].shape[1:],\n        volume_origin=op.inputs[2],\n        detector_origin=op.inputs[3],\n        volume_spacing=op.inputs[4],\n        detector_spacing=op.inputs[5],\n        source_2_isocenter_distance=op.inputs[6],\n        source_2_detector_distance=op.inputs[7],\n        central_ray_vectors=op.inputs[8],\n    )\n    return [proj, tf.stop_gradient(op.inputs[1]),  tf.stop_gradient(op.inputs[2]),  tf.stop_gradient(op.inputs[3]), tf.stop_gradient(op.inputs[4]),\n            tf.stop_gradient(op.inputs[5]),  tf.stop_gradient(op.inputs[6]),  tf.stop_gradient(op.inputs[7]), tf.stop_gradient(op.inputs[8])]\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_2d/#pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d.fan_backprojection2d","title":"pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d.fan_backprojection2d","text":"<pre><code>fan_backprojection2d(sinogram, geometry)\n</code></pre> <p>Wrapper function for making the layer call. Args:     volume:     Input volume to project.     geometry:   Corresponding GeometryFan2D Object defining parameters. Returns:         Initialized lme_custom_ops.fan_backprojection2d layer.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_2d.py</code> <pre><code>def fan_backprojection2d(sinogram, geometry):\n    \"\"\"\n    Wrapper function for making the layer call.\n    Args:\n        volume:     Input volume to project.\n        geometry:   Corresponding GeometryFan2D Object defining parameters.\n    Returns:\n            Initialized lme_custom_ops.fan_backprojection2d layer.\n    \"\"\"\n    batch = np.shape(sinogram)[0]\n    return pyronn_layers.fan_backprojection2d(sinogram,\n                                              volume_shape=geometry.volume_shape,\n                                              volume_origin=np.broadcast_to(geometry.volume_origin, [batch, *np.shape(geometry.volume_origin)]),\n                                              detector_origin=np.broadcast_to(geometry.detector_origin, [batch, *np.shape(geometry.detector_origin)]),\n                                              volume_spacing=np.broadcast_to(geometry.volume_spacing, [batch, *np.shape(geometry.volume_spacing)]),\n                                              detector_spacing=np.broadcast_to(geometry.detector_spacing, [batch, *np.shape(geometry.detector_spacing)]),\n                                              source_2_isocenter_distance=np.broadcast_to(geometry.source_isocenter_distance, [batch, *np.shape(geometry.source_isocenter_distance)]),\n                                              source_2_detector_distance=np.broadcast_to(geometry.source_detector_distance, [batch, *np.shape(geometry.source_detector_distance)]),\n                                              central_ray_vectors=np.broadcast_to(geometry.trajectory, [batch, *np.shape(geometry.trajectory)]))\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_2d/#pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d._backproject_grad","title":"pyronn.ct_reconstruction.layers.tensorflow.backprojection_2d._backproject_grad","text":"<pre><code>_backproject_grad(op, grad)\n</code></pre> <p>Compute the gradient of the backprojector op by invoking the forward projector.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_2d.py</code> <pre><code>@ops.RegisterGradient(\"FanBackprojection2D\")\ndef _backproject_grad(op, grad):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n        Compute the gradient of the backprojector op by invoking the forward projector.\n    '''\n    proj = pyronn_layers.fan_projection2d(\n        volume=grad,\n        projection_shape=op.inputs[0].shape[1:],\n        volume_origin=op.inputs[2],\n        detector_origin=op.inputs[3],\n        volume_spacing=op.inputs[4],\n        detector_spacing=op.inputs[5],\n        source_2_isocenter_distance=op.inputs[6],\n        source_2_detector_distance=op.inputs[7],\n        central_ray_vectors=op.inputs[8],\n    )\n    return [proj, tf.stop_gradient(op.inputs[1]),  tf.stop_gradient(op.inputs[2]),  tf.stop_gradient(op.inputs[3]), tf.stop_gradient(op.inputs[4]),\n            tf.stop_gradient(op.inputs[5]),  tf.stop_gradient(op.inputs[6]),  tf.stop_gradient(op.inputs[7]), tf.stop_gradient(op.inputs[8])]\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_3d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_3d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_3d/#pyronn.ct_reconstruction.layers.tensorflow.backprojection_3d.cone_backprojection3d","title":"pyronn.ct_reconstruction.layers.tensorflow.backprojection_3d.cone_backprojection3d","text":"<pre><code>cone_backprojection3d(sinogram, geometry, hardware_interp=True)\n</code></pre> <p>Wrapper function for making the layer call. Args:     volume:             Input volume to project.     geometry:           Corresponding GeometryCone3D Object defining parameters.     hardware_interp:    Controls if interpolation is done by GPU  Returns:         Initialized lme_custom_ops.cone_backprojection3d layer.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_3d.py</code> <pre><code>def cone_backprojection3d(sinogram, geometry, hardware_interp=True):\n    \"\"\"\n    Wrapper function for making the layer call.\n    Args:\n        volume:             Input volume to project.\n        geometry:           Corresponding GeometryCone3D Object defining parameters.\n        hardware_interp:    Controls if interpolation is done by GPU \n    Returns:\n            Initialized lme_custom_ops.cone_backprojection3d layer.\n    \"\"\"\n    batch = np.shape(sinogram)[0]\n    step_size=1.0\n    return pyronn_layers.cone_backprojection3d(sinogram,\n                                               volume_shape=geometry.volume_shape,\n                                               volume_origin=np.broadcast_to(geometry.volume_origin, [batch, *np.shape(geometry.volume_origin)]),\n                                               volume_spacing=np.broadcast_to(geometry.volume_spacing, [batch, *np.shape(geometry.volume_spacing)]),\n                                               projection_matrices=np.broadcast_to(geometry.trajectory, [batch, *np.shape(geometry.trajectory)]),\n                                               hardware_interp=hardware_interp,\n                                               step_size=np.broadcast_to(step_size, [batch, *np.shape(step_size)]),\n                                               projection_multiplier=np.broadcast_to(geometry.projection_multiplier, [batch, *np.shape(geometry.projection_multiplier)]))\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/backprojection_3d/#pyronn.ct_reconstruction.layers.tensorflow.backprojection_3d._backproject_grad","title":"pyronn.ct_reconstruction.layers.tensorflow.backprojection_3d._backproject_grad","text":"<pre><code>_backproject_grad(op, grad)\n</code></pre> <p>Compute the gradient of the backprojector op by invoking the forward projector.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/backprojection_3d.py</code> <pre><code>@ops.RegisterGradient(\"ConeBackprojection3D\")\ndef _backproject_grad(op, grad):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n        Compute the gradient of the backprojector op by invoking the forward projector.\n    '''\n    proj = pyronn_layers.cone_projection3d(\n        volume=grad,\n        projection_shape=op.inputs[0].shape[1:],\n        volume_origin=op.inputs[2],\n        volume_spacing=op.inputs[3],\n        projection_matrices=op.inputs[4],\n        hardware_interp=op.get_attr(\"hardware_interp\"),\n        step_size=op.inputs[5],\n        projection_multiplier=op.inputs[6],\n    )\n    return [proj, tf.stop_gradient(op.inputs[1]), tf.stop_gradient(op.inputs[2]), tf.stop_gradient(op.inputs[3]), tf.stop_gradient(op.inputs[4]), tf.stop_gradient(op.inputs[5]), tf.stop_gradient(op.inputs[6])]\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_2d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/tensorflow/projection_2d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_2d/#pyronn.ct_reconstruction.layers.tensorflow.projection_2d.parallel_projection2d","title":"pyronn.ct_reconstruction.layers.tensorflow.projection_2d.parallel_projection2d","text":"<pre><code>parallel_projection2d(volume, geometry)\n</code></pre> <p>Wrapper function for making the layer call. Args:     volume:     Input volume to project.     geometry:   Corresponding GeometryParallel2D Object defining parameters. Returns:         Initialized lme_custom_ops.parallel_projection2d layer.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/projection_2d.py</code> <pre><code>def parallel_projection2d(volume, geometry):\n    \"\"\"\n    Wrapper function for making the layer call.\n    Args:\n        volume:     Input volume to project.\n        geometry:   Corresponding GeometryParallel2D Object defining parameters.\n    Returns:\n            Initialized lme_custom_ops.parallel_projection2d layer.\n    \"\"\"\n    batch = np.shape(volume)[0]\n    return pyronn_layers.parallel_projection2d(volume,\n                                               projection_shape=geometry.sinogram_shape,\n                                               volume_origin=np.broadcast_to(geometry.volume_origin, [batch, *np.shape(geometry.volume_origin)]),\n                                               detector_origin=np.broadcast_to(geometry.detector_origin, [batch, *np.shape(geometry.detector_origin)]),\n                                               volume_spacing=np.broadcast_to(geometry.volume_spacing, [batch, *np.shape(geometry.volume_spacing)]),\n                                               detector_spacing=np.broadcast_to(geometry.detector_spacing, [batch, *np.shape(geometry.detector_spacing)]),\n                                               ray_vectors=np.broadcast_to(geometry.trajectory, [batch, *np.shape(geometry.trajectory)]))\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_2d/#pyronn.ct_reconstruction.layers.tensorflow.projection_2d._project_grad","title":"pyronn.ct_reconstruction.layers.tensorflow.projection_2d._project_grad","text":"<pre><code>_project_grad(op, grad)\n</code></pre> <p>Compute the gradient of the projection op by invoking the backprojector.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/projection_2d.py</code> <pre><code>@ops.RegisterGradient(\"FanProjection2D\")\ndef _project_grad(op, grad):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n        Compute the gradient of the projection op by invoking the backprojector.\n    '''\n    reco = pyronn_layers.fan_backprojection2d(\n        sinogram=grad,\n        volume_shape=op.inputs[0].shape[1:],\n        volume_origin=op.inputs[2],\n        detector_origin=op.inputs[3],\n        volume_spacing=op.inputs[4],\n        detector_spacing=op.inputs[5],\n        source_2_isocenter_distance=op.inputs[6],\n        source_2_detector_distance=op.inputs[7],\n        central_ray_vectors=op.inputs[8],\n    )\n    return [reco, tf.stop_gradient(op.inputs[1]), tf.stop_gradient(op.inputs[2]), tf.stop_gradient(op.inputs[3]), tf.stop_gradient(op.inputs[4]), tf.stop_gradient(op.inputs[5]), tf.stop_gradient(op.inputs[6]),\n            tf.stop_gradient(op.inputs[7]), tf.stop_gradient(op.inputs[8])]\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_2d/#pyronn.ct_reconstruction.layers.tensorflow.projection_2d.fan_projection2d","title":"pyronn.ct_reconstruction.layers.tensorflow.projection_2d.fan_projection2d","text":"<pre><code>fan_projection2d(volume, geometry)\n</code></pre> <p>Wrapper function for making the layer call. Args:     volume:     Input volume to project.     geometry:   Corresponding GeometryFan2D Object defining parameters. Returns:         Initialized lme_custom_ops.fan_projection2d layer.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/projection_2d.py</code> <pre><code>def fan_projection2d(volume, geometry):\n    \"\"\"\n    Wrapper function for making the layer call.\n    Args:\n        volume:     Input volume to project.\n        geometry:   Corresponding GeometryFan2D Object defining parameters.\n    Returns:\n            Initialized lme_custom_ops.fan_projection2d layer.\n    \"\"\"\n    batch = np.shape(volume)[0]\n    return pyronn_layers.fan_projection2d(volume,\n                                          projection_shape=geometry.sinogram_shape,\n                                          volume_origin=np.broadcast_to(geometry.volume_origin, [batch, *np.shape(geometry.volume_origin)]),\n                                          detector_origin=np.broadcast_to(geometry.detector_origin, [batch, *np.shape(geometry.detector_origin)]),\n                                          volume_spacing=np.broadcast_to(geometry.volume_spacing, [batch, *np.shape(geometry.volume_spacing)]),\n                                          detector_spacing=np.broadcast_to(geometry.detector_spacing, [batch, *np.shape(geometry.detector_spacing)]),\n                                          source_2_isocenter_distance=np.broadcast_to(geometry.source_isocenter_distance, [batch, *np.shape(geometry.source_isocenter_distance)]),\n                                          source_2_detector_distance=np.broadcast_to(geometry.source_detector_distance, [batch, *np.shape(geometry.source_detector_distance)]),\n                                          central_ray_vectors=np.broadcast_to(geometry.trajectory, [batch, *np.shape(geometry.trajectory)]))\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_2d/#pyronn.ct_reconstruction.layers.tensorflow.projection_2d._project_grad","title":"pyronn.ct_reconstruction.layers.tensorflow.projection_2d._project_grad","text":"<pre><code>_project_grad(op, grad)\n</code></pre> <p>Compute the gradient of the projection op by invoking the backprojector.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/projection_2d.py</code> <pre><code>@ops.RegisterGradient(\"FanProjection2D\")\ndef _project_grad(op, grad):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n        Compute the gradient of the projection op by invoking the backprojector.\n    '''\n    reco = pyronn_layers.fan_backprojection2d(\n        sinogram=grad,\n        volume_shape=op.inputs[0].shape[1:],\n        volume_origin=op.inputs[2],\n        detector_origin=op.inputs[3],\n        volume_spacing=op.inputs[4],\n        detector_spacing=op.inputs[5],\n        source_2_isocenter_distance=op.inputs[6],\n        source_2_detector_distance=op.inputs[7],\n        central_ray_vectors=op.inputs[8],\n    )\n    return [reco, tf.stop_gradient(op.inputs[1]), tf.stop_gradient(op.inputs[2]), tf.stop_gradient(op.inputs[3]), tf.stop_gradient(op.inputs[4]), tf.stop_gradient(op.inputs[5]), tf.stop_gradient(op.inputs[6]),\n            tf.stop_gradient(op.inputs[7]), tf.stop_gradient(op.inputs[8])]\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_3d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/tensorflow/projection_3d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_3d/#pyronn.ct_reconstruction.layers.tensorflow.projection_3d.cone_projection3d","title":"pyronn.ct_reconstruction.layers.tensorflow.projection_3d.cone_projection3d","text":"<pre><code>cone_projection3d(volume, geometry, hardware_interp=True, step_size=1.0)\n</code></pre> <p>Wrapper function for making the layer call. Args:     volume:             Input volume to project.     geometry:           Corresponding GeometryCone3D Object defining parameters.     hardware_interp:    Controls if interpolation is done by GPU.     step_size:          step_size along ray direction in voxel. Returns:         Initialized lme_custom_ops.cone_projection3d layer.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/projection_3d.py</code> <pre><code>def cone_projection3d(volume, geometry, hardware_interp=True, step_size=1.0):\n    \"\"\"\n    Wrapper function for making the layer call.\n    Args:\n        volume:             Input volume to project.\n        geometry:           Corresponding GeometryCone3D Object defining parameters.\n        hardware_interp:    Controls if interpolation is done by GPU.\n        step_size:          step_size along ray direction in voxel.\n    Returns:\n            Initialized lme_custom_ops.cone_projection3d layer.\n    \"\"\"\n    batch = np.shape(volume)[0]\n    return pyronn_layers.cone_projection3d(volume,\n                                           projection_shape=geometry.sinogram_shape,\n                                           volume_origin=np.broadcast_to(geometry.volume_origin, [batch, *np.shape(geometry.volume_origin)]),\n                                           volume_spacing=np.broadcast_to(geometry.volume_spacing, [batch, *np.shape(geometry.volume_spacing)]),\n                                           projection_matrices=np.broadcast_to(geometry.trajectory, [batch, *np.shape(geometry.trajectory)]),\n                                           step_size=np.broadcast_to(step_size, [batch, *np.shape(step_size)]),\n                                           projection_multiplier=np.broadcast_to(geometry.projection_multiplier, [batch, *np.shape(geometry.projection_multiplier)]),\n                                           hardware_interp=hardware_interp)\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/tensorflow/projection_3d/#pyronn.ct_reconstruction.layers.tensorflow.projection_3d._project_grad","title":"pyronn.ct_reconstruction.layers.tensorflow.projection_3d._project_grad","text":"<pre><code>_project_grad(op, grad)\n</code></pre> <p>Compute the gradient of the projection op by invoking the backprojector.</p> Source code in <code>pyronn/ct_reconstruction/layers/tensorflow/projection_3d.py</code> <pre><code>@ops.RegisterGradient(\"ConeProjection3D\")\ndef _project_grad(op, grad):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    '''\n    Compute the gradient of the projection op by invoking the backprojector.\n    '''\n    reco = pyronn_layers.cone_backprojection3d(\n        sinogram=grad,\n        volume_shape=op.inputs[0].shape[1:],\n        volume_origin=op.inputs[2],\n        volume_spacing=op.inputs[3],\n        projection_matrices=op.inputs[4],\n        step_size=op.inputs[5],\n        projection_multiplier=op.inputs[6],\n        hardware_interp=op.get_attr(\"hardware_interp\")\n    )\n    return [reco, tf.stop_gradient(op.inputs[1]), tf.stop_gradient(op.inputs[2]), tf.stop_gradient(op.inputs[3]), tf.stop_gradient(op.inputs[4]), tf.stop_gradient(op.inputs[5]), tf.stop_gradient(op.inputs[6])]\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/backprojection_2d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/torch/backprojection_2d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/torch/backprojection_2d/#pyronn.ct_reconstruction.layers.torch.backprojection_2d.ParallelBackProjection2DFunction","title":"pyronn.ct_reconstruction.layers.torch.backprojection_2d.ParallelBackProjection2DFunction","text":"<p>               Bases: <code>Function</code></p>"},{"location":"reference/ct_reconstruction/layers/torch/backprojection_2d/#pyronn.ct_reconstruction.layers.torch.backprojection_2d.ParallelBackProjection2D","title":"pyronn.ct_reconstruction.layers.torch.backprojection_2d.ParallelBackProjection2D","text":"<pre><code>ParallelBackProjection2D()\n</code></pre> <p>               Bases: <code>Module</code></p> Source code in <code>pyronn/ct_reconstruction/layers/torch/backprojection_2d.py</code> <pre><code>def __init__(self):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super(ParallelBackProjection2D, self).__init__()\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/backprojection_2d/#pyronn.ct_reconstruction.layers.torch.backprojection_2d.FanBackProjection2DFunction","title":"pyronn.ct_reconstruction.layers.torch.backprojection_2d.FanBackProjection2DFunction","text":"<p>               Bases: <code>Function</code></p>"},{"location":"reference/ct_reconstruction/layers/torch/backprojection_2d/#pyronn.ct_reconstruction.layers.torch.backprojection_2d.FanBackProjection2D","title":"pyronn.ct_reconstruction.layers.torch.backprojection_2d.FanBackProjection2D","text":"<pre><code>FanBackProjection2D()\n</code></pre> <p>               Bases: <code>Module</code></p> Source code in <code>pyronn/ct_reconstruction/layers/torch/backprojection_2d.py</code> <pre><code>def __init__(self):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super(FanBackProjection2D, self).__init__()\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/backprojection_3d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/torch/backprojection_3d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/torch/backprojection_3d/#pyronn.ct_reconstruction.layers.torch.backprojection_3d.ConeBackProjection3DFunction","title":"pyronn.ct_reconstruction.layers.torch.backprojection_3d.ConeBackProjection3DFunction","text":"<p>               Bases: <code>Function</code></p>"},{"location":"reference/ct_reconstruction/layers/torch/backprojection_3d/#pyronn.ct_reconstruction.layers.torch.backprojection_3d.ConeBackProjection3D","title":"pyronn.ct_reconstruction.layers.torch.backprojection_3d.ConeBackProjection3D","text":"<pre><code>ConeBackProjection3D(hardware_interp=False)\n</code></pre> <p>               Bases: <code>Module</code></p> Source code in <code>pyronn/ct_reconstruction/layers/torch/backprojection_3d.py</code> <pre><code>def __init__(self, hardware_interp=False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super(ConeBackProjection3D, self).__init__()\n    self.hardware_interp = torch.Tensor([hardware_interp]).cpu()\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/projection_2d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/torch/projection_2d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/torch/projection_2d/#pyronn.ct_reconstruction.layers.torch.projection_2d.ParallelProjection2DFunction","title":"pyronn.ct_reconstruction.layers.torch.projection_2d.ParallelProjection2DFunction","text":"<p>               Bases: <code>Function</code></p>"},{"location":"reference/ct_reconstruction/layers/torch/projection_2d/#pyronn.ct_reconstruction.layers.torch.projection_2d.ParallelProjection2DFunction.forward","title":"forward  <code>staticmethod</code>","text":"<pre><code>forward(ctx, input: Tensor, sinogram_shape: Tensor, volume_origin: Tensor, detector_origin: Tensor, volume_spacing: Tensor, detector_spacing: Tensor, trajectory) -&gt; Tensor\n</code></pre> <p>Forward operator of 2D parallel projection Args:          input:              volume to be projected         sinogram_shape:     number_of_projections x detector_width         volume_origin:      origin of the world coordinate system w.r.t. the volume array (tensor)         ...</p> Source code in <code>pyronn/ct_reconstruction/layers/torch/projection_2d.py</code> <pre><code>@staticmethod\ndef forward(ctx, input:Tensor, sinogram_shape:Tensor, volume_origin:Tensor, detector_origin:Tensor, volume_spacing:Tensor, detector_spacing:Tensor, trajectory)-&gt;Tensor:\n    \"\"\"\n    Forward operator of 2D parallel projection\n    Args: \n            input:              volume to be projected\n            sinogram_shape:     number_of_projections x detector_width\n            volume_origin:      origin of the world coordinate system w.r.t. the volume array (tensor)\n            ...\n    \"\"\"\n    outputs = pyronn_layers.parallel_projection2d(input,sinogram_shape, volume_origin,detector_origin,volume_spacing,detector_spacing,trajectory)\n\n    ctx.volume_shape        = torch.tensor(input.shape[1:]).cuda()\n    ctx.volume_origin       = volume_origin\n    ctx.detector_origin     = detector_origin\n    ctx.volume_spacing      = volume_spacing\n    ctx.detector_spacing    = detector_spacing\n    ctx.trajectory          = trajectory\n\n    return outputs\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/projection_2d/#pyronn.ct_reconstruction.layers.torch.projection_2d.ParallelProjection2D","title":"pyronn.ct_reconstruction.layers.torch.projection_2d.ParallelProjection2D","text":"<pre><code>ParallelProjection2D()\n</code></pre> <p>               Bases: <code>Module</code></p> Source code in <code>pyronn/ct_reconstruction/layers/torch/projection_2d.py</code> <pre><code>def __init__(self):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super(ParallelProjection2D, self).__init__()\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/projection_2d/#pyronn.ct_reconstruction.layers.torch.projection_2d.FanProjection2DFunction","title":"pyronn.ct_reconstruction.layers.torch.projection_2d.FanProjection2DFunction","text":"<p>               Bases: <code>Function</code></p>"},{"location":"reference/ct_reconstruction/layers/torch/projection_2d/#pyronn.ct_reconstruction.layers.torch.projection_2d.FanProjection2DFunction.forward","title":"forward  <code>staticmethod</code>","text":"<pre><code>forward(ctx, input: Tensor, sinogram_shape: Tensor, volume_origin: Tensor, detector_origin: Tensor, volume_spacing: Tensor, detector_spacing: Tensor, source_isocenter_distance: Tensor, source_detector_distance: Tensor, trajectory: Tensor) -&gt; Tensor\n</code></pre> <p>Forward operator of 2D fan projection Args:          input:              volume to be projected         sinogram_shape:     number_of_projections x detector_width         volume_origin:      origin of the world coordinate system w.r.t. the volume array (tensor)         ...</p> Source code in <code>pyronn/ct_reconstruction/layers/torch/projection_2d.py</code> <pre><code>@staticmethod\ndef forward(ctx, input:Tensor, sinogram_shape:Tensor, volume_origin:Tensor, detector_origin:Tensor, volume_spacing:Tensor, detector_spacing:Tensor, source_isocenter_distance:Tensor, source_detector_distance:Tensor, trajectory:Tensor)-&gt;Tensor:\n    \"\"\"\n    Forward operator of 2D fan projection\n    Args: \n            input:              volume to be projected\n            sinogram_shape:     number_of_projections x detector_width\n            volume_origin:      origin of the world coordinate system w.r.t. the volume array (tensor)\n            ...\n    \"\"\"\n    outputs = pyronn_layers.fan_projection2d(input,sinogram_shape, volume_origin,detector_origin,volume_spacing,detector_spacing,source_isocenter_distance,source_detector_distance,trajectory)\n\n    ctx.volume_shape        = torch.tensor(input.shape[1:]).cuda()\n    ctx.volume_origin       = volume_origin\n    ctx.detector_origin     = detector_origin\n    ctx.volume_spacing      = volume_spacing\n    ctx.detector_spacing    = detector_spacing\n    ctx.source_isocenter_distance      = source_isocenter_distance\n    ctx.source_detector_distance    = source_detector_distance\n    ctx.trajectory          = trajectory\n\n    return outputs\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/projection_2d/#pyronn.ct_reconstruction.layers.torch.projection_2d.FanProjection2D","title":"pyronn.ct_reconstruction.layers.torch.projection_2d.FanProjection2D","text":"<pre><code>FanProjection2D()\n</code></pre> <p>               Bases: <code>Module</code></p> Source code in <code>pyronn/ct_reconstruction/layers/torch/projection_2d.py</code> <pre><code>def __init__(self):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super(FanProjection2D, self).__init__()\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/projection_3d/","title":"Reference for <code>pyronn/ct_reconstruction/layers/torch/projection_3d.py</code>","text":""},{"location":"reference/ct_reconstruction/layers/torch/projection_3d/#pyronn.ct_reconstruction.layers.torch.projection_3d.ConeProjection3DFunction","title":"pyronn.ct_reconstruction.layers.torch.projection_3d.ConeProjection3DFunction","text":"<p>               Bases: <code>Function</code></p>"},{"location":"reference/ct_reconstruction/layers/torch/projection_3d/#pyronn.ct_reconstruction.layers.torch.projection_3d.ConeProjection3DFunction.forward","title":"forward  <code>staticmethod</code>","text":"<pre><code>forward(ctx, input: Tensor, sinogram_shape: Tensor, volume_origin: Tensor, volume_spacing: Tensor, trajectory: Tensor, projection_multiplier: Tensor, step_size: Tensor, hardware_interp: Tensor) -&gt; Tensor\n</code></pre> <p>Forward operator of 2D fan projection Args:          input:              volume to be projected         sinogram_shape:     number_of_projections x detector_width         volume_origin:      origin of the world coordinate system w.r.t. the volume array (tensor)         ...</p> Source code in <code>pyronn/ct_reconstruction/layers/torch/projection_3d.py</code> <pre><code>@staticmethod\ndef forward(ctx, input:Tensor, sinogram_shape:Tensor, volume_origin:Tensor, volume_spacing:Tensor, trajectory:Tensor,\n                 projection_multiplier:Tensor, step_size:Tensor, hardware_interp:Tensor)-&gt;Tensor:\n    \"\"\"\n    Forward operator of 2D fan projection\n    Args: \n            input:              volume to be projected\n            sinogram_shape:     number_of_projections x detector_width\n            volume_origin:      origin of the world coordinate system w.r.t. the volume array (tensor)\n            ...\n    \"\"\"\n    outputs = pyronn_layers.cone_projection3d(input,sinogram_shape, volume_origin,volume_spacing,trajectory, step_size, hardware_interp)\n\n    ctx.volume_shape            = torch.tensor(input.shape[1:]).cuda()\n    ctx.volume_origin           = volume_origin\n    ctx.volume_spacing          = volume_spacing\n    ctx.trajectory              = trajectory\n    ctx.projection_multiplier   = projection_multiplier\n    ctx.hardware_interp         = hardware_interp\n\n    return outputs\n</code></pre>"},{"location":"reference/ct_reconstruction/layers/torch/projection_3d/#pyronn.ct_reconstruction.layers.torch.projection_3d.ConeProjection3D","title":"pyronn.ct_reconstruction.layers.torch.projection_3d.ConeProjection3D","text":"<pre><code>ConeProjection3D(hardware_interp=False)\n</code></pre> <p>               Bases: <code>Module</code></p> Source code in <code>pyronn/ct_reconstruction/layers/torch/projection_3d.py</code> <pre><code>def __init__(self, hardware_interp = False):\n    # TODO: Document this function on your own. Could not be documented by the model.\n    # TODO: Document this function on your own. Could not be documented by the model.\n    super(ConeProjection3D, self).__init__()\n    self.hardware_interp = torch.Tensor([hardware_interp]).cpu()\n</code></pre>"},{"location":"scripts/gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>import re\nimport subprocess\nfrom collections import defaultdict\nfrom pathlib import Path\n</pre> import re import subprocess from collections import defaultdict from pathlib import Path In\u00a0[\u00a0]: Copied! <pre># Constants\nFILE = Path(__file__).resolve()\nPACKAGE_DIR = FILE.parents[2] / \"pyronn\"\nREFERENCE_DIR = PACKAGE_DIR.parent / \"docs/reference\"\n</pre> # Constants FILE = Path(__file__).resolve() PACKAGE_DIR = FILE.parents[2] / \"pyronn\" REFERENCE_DIR = PACKAGE_DIR.parent / \"docs/reference\" In\u00a0[\u00a0]: Copied! <pre>def extract_classes_and_functions(filepath: Path) -&gt; tuple:\n    \"\"\"Extracts class and function names from a given Python file.\"\"\"\n    content = filepath.read_text(encoding=\"utf-8\")\n    class_pattern = r\"(?:^|\\n)class\\s(\\w+)(?:\\(|:)\"\n    func_pattern = r\"(?:^|\\n)def\\s(\\w+)\\(\"\n\n    classes = re.findall(class_pattern, content)\n    functions = re.findall(func_pattern, content)\n\n    return classes, functions\n</pre> def extract_classes_and_functions(filepath: Path) -&gt; tuple:     \"\"\"Extracts class and function names from a given Python file.\"\"\"     content = filepath.read_text(encoding=\"utf-8\")     class_pattern = r\"(?:^|\\n)class\\s(\\w+)(?:\\(|:)\"     func_pattern = r\"(?:^|\\n)def\\s(\\w+)\\(\"      classes = re.findall(class_pattern, content)     functions = re.findall(func_pattern, content)      return classes, functions In\u00a0[\u00a0]: Copied! <pre>def create_markdown(\n    py_filepath: Path, module_path: str, classes: list, functions: list\n):\n    \"\"\"Creates a Markdown file containing the API reference for the given Python module.\"\"\"\n    md_filepath = py_filepath.with_suffix(\".md\")\n    exists = md_filepath.exists()\n\n    # Extract module docstring\n    py_filepath = Path(str(py_filepath).replace(str(REFERENCE_DIR), str(PACKAGE_DIR)))\n    content = py_filepath.read_text(encoding=\"utf-8\")\n    module_docstring = \"\"\n    if content.startswith('\"\"\"') or content.startswith(\"'''\"):\n        end_index = content.find(content[:3], 3)\n        if end_index != -1:\n            module_docstring = content[3:end_index].strip()\n\n    # Read existing content and keep header content between first two ---\n    header_content = f\"{module_docstring}\\n\\n\" if module_docstring else \"\"\n\n    module_name = module_path.replace(\".__init__\", \"\")\n    module_path = module_path.replace(\".\", \"/\")\n    title_content = f\"# Reference for `{module_path}.py`\\n\\n\"\n    md_content = [\"&lt;br&gt;\\n\"] + [\n        f\"## ::: {module_name}.{class_name}\\n\\n&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;\\n\"\n        for class_name in classes\n    ]\n    md_content.extend(\n        f\"## ::: {module_name}.{func_name}\\n\\n&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;\\n\"\n        for func_name in functions\n    )\n    md_content[-1] = md_content[-1].replace(\n        \"&lt;hr&gt;&lt;br&gt;\", \"\"\n    )  # remove last horizontal line\n    md_content = title_content + header_content + \"\\n\".join(md_content)\n    if not md_content.endswith(\"\\n\"):\n        md_content += \"\\n\"\n\n    md_filepath.parent.mkdir(parents=True, exist_ok=True)\n    md_filepath.write_text(md_content)\n\n    if not exists:\n        # Add new markdown file to the git staging area\n        print(f\"Created new file '{md_filepath}'\")\n        subprocess.run(\n            [\"git\", \"add\", \"-f\", str(md_filepath)], check=True, cwd=PACKAGE_DIR\n        )\n\n    return md_filepath.relative_to(PACKAGE_DIR.parent)\n</pre> def create_markdown(     py_filepath: Path, module_path: str, classes: list, functions: list ):     \"\"\"Creates a Markdown file containing the API reference for the given Python module.\"\"\"     md_filepath = py_filepath.with_suffix(\".md\")     exists = md_filepath.exists()      # Extract module docstring     py_filepath = Path(str(py_filepath).replace(str(REFERENCE_DIR), str(PACKAGE_DIR)))     content = py_filepath.read_text(encoding=\"utf-8\")     module_docstring = \"\"     if content.startswith('\"\"\"') or content.startswith(\"'''\"):         end_index = content.find(content[:3], 3)         if end_index != -1:             module_docstring = content[3:end_index].strip()      # Read existing content and keep header content between first two ---     header_content = f\"{module_docstring}\\n\\n\" if module_docstring else \"\"      module_name = module_path.replace(\".__init__\", \"\")     module_path = module_path.replace(\".\", \"/\")     title_content = f\"# Reference for `{module_path}.py`\\n\\n\"     md_content = [\"\\n\"] + [         f\"## ::: {module_name}.{class_name}\\n\\n\\n\"         for class_name in classes     ]     md_content.extend(         f\"## ::: {module_name}.{func_name}\\n\\n\\n\"         for func_name in functions     )     md_content[-1] = md_content[-1].replace(         \"\", \"\"     )  # remove last horizontal line     md_content = title_content + header_content + \"\\n\".join(md_content)     if not md_content.endswith(\"\\n\"):         md_content += \"\\n\"      md_filepath.parent.mkdir(parents=True, exist_ok=True)     md_filepath.write_text(md_content)      if not exists:         # Add new markdown file to the git staging area         print(f\"Created new file '{md_filepath}'\")         subprocess.run(             [\"git\", \"add\", \"-f\", str(md_filepath)], check=True, cwd=PACKAGE_DIR         )      return md_filepath.relative_to(PACKAGE_DIR.parent) In\u00a0[\u00a0]: Copied! <pre>def nested_dict() -&gt; defaultdict:\n    \"\"\"Creates and returns a nested defaultdict.\"\"\"\n    return defaultdict(nested_dict)\n</pre> def nested_dict() -&gt; defaultdict:     \"\"\"Creates and returns a nested defaultdict.\"\"\"     return defaultdict(nested_dict) In\u00a0[\u00a0]: Copied! <pre>def sort_nested_dict(d: dict) -&gt; dict:\n    \"\"\"Sorts a nested dictionary recursively.\"\"\"\n    return {\n        key: sort_nested_dict(value) if isinstance(value, dict) else value\n        for key, value in sorted(d.items())\n    }\n</pre> def sort_nested_dict(d: dict) -&gt; dict:     \"\"\"Sorts a nested dictionary recursively.\"\"\"     return {         key: sort_nested_dict(value) if isinstance(value, dict) else value         for key, value in sorted(d.items())     } In\u00a0[\u00a0]: Copied! <pre>def create_nav_menu_yaml(nav_items: list, save: bool = False):\n    \"\"\"Creates a YAML file for the navigation menu based on the provided list of items.\"\"\"\n    nav_tree = nested_dict()\n\n    for item_str in nav_items:\n        item = Path(item_str)\n        parts = item.parts\n        current_level = nav_tree[\"Reference\"]\n        for part in parts[\n            2:-1\n        ]:  # skip the first two parts (docs and reference) and the last part (filename)\n            current_level = current_level[part.capitalize()]\n\n        md_file_name = parts[-1].replace(\".md\", \"\").capitalize()\n        current_level[md_file_name] = str(item).replace(\"docs/\", \"\")\n\n    nav_tree_sorted = sort_nested_dict(nav_tree)\n\n    def _dict_to_yaml(d, level=0):\n        \"\"\"Converts a nested dictionary to a YAML-formatted string with indentation.\"\"\"\n        yaml_str = \"\"\n        indent = \"  \" * level\n        for k, v in d.items():\n            if isinstance(v, dict):\n                yaml_str += f\"{indent}- {k}:\\n{_dict_to_yaml(v, level + 1)}\"\n            else:\n                yaml_str += f\"{indent}- {k}: {str(v)}\\n\"\n        return yaml_str\n\n    # Print updated YAML reference section\n    print(\n        \"Scan complete, new mkdocs.yaml reference section is:\\n\\n\",\n        _dict_to_yaml(nav_tree_sorted),\n    )\n\n    # Save new YAML reference section\n    if save:\n        (PACKAGE_DIR.parent / \"nav_menu_updated.yml\").write_text(\n            _dict_to_yaml(nav_tree_sorted)\n        )\n</pre> def create_nav_menu_yaml(nav_items: list, save: bool = False):     \"\"\"Creates a YAML file for the navigation menu based on the provided list of items.\"\"\"     nav_tree = nested_dict()      for item_str in nav_items:         item = Path(item_str)         parts = item.parts         current_level = nav_tree[\"Reference\"]         for part in parts[             2:-1         ]:  # skip the first two parts (docs and reference) and the last part (filename)             current_level = current_level[part.capitalize()]          md_file_name = parts[-1].replace(\".md\", \"\").capitalize()         current_level[md_file_name] = str(item).replace(\"docs/\", \"\")      nav_tree_sorted = sort_nested_dict(nav_tree)      def _dict_to_yaml(d, level=0):         \"\"\"Converts a nested dictionary to a YAML-formatted string with indentation.\"\"\"         yaml_str = \"\"         indent = \"  \" * level         for k, v in d.items():             if isinstance(v, dict):                 yaml_str += f\"{indent}- {k}:\\n{_dict_to_yaml(v, level + 1)}\"             else:                 yaml_str += f\"{indent}- {k}: {str(v)}\\n\"         return yaml_str      # Print updated YAML reference section     print(         \"Scan complete, new mkdocs.yaml reference section is:\\n\\n\",         _dict_to_yaml(nav_tree_sorted),     )      # Save new YAML reference section     if save:         (PACKAGE_DIR.parent / \"nav_menu_updated.yml\").write_text(             _dict_to_yaml(nav_tree_sorted)         ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"Main function to extract class and function names, create Markdown files, and generate a YAML navigation menu.\"\"\"\n    nav_items = []\n\n    for py_filepath in PACKAGE_DIR.rglob(\"*.py\"):\n        classes, functions = extract_classes_and_functions(py_filepath)\n\n        if classes or functions:\n            py_filepath_rel = py_filepath.relative_to(PACKAGE_DIR)\n            md_filepath = REFERENCE_DIR / py_filepath_rel\n            module_path = f\"{PACKAGE_DIR.name}.{py_filepath_rel.with_suffix('').as_posix().replace('/', '.')}\"\n            md_rel_filepath = create_markdown(\n                md_filepath, module_path, classes, functions\n            )\n            nav_items.append(str(md_rel_filepath))\n\n    create_nav_menu_yaml(nav_items)\n</pre> def main():     \"\"\"Main function to extract class and function names, create Markdown files, and generate a YAML navigation menu.\"\"\"     nav_items = []      for py_filepath in PACKAGE_DIR.rglob(\"*.py\"):         classes, functions = extract_classes_and_functions(py_filepath)          if classes or functions:             py_filepath_rel = py_filepath.relative_to(PACKAGE_DIR)             md_filepath = REFERENCE_DIR / py_filepath_rel             module_path = f\"{PACKAGE_DIR.name}.{py_filepath_rel.with_suffix('').as_posix().replace('/', '.')}\"             md_rel_filepath = create_markdown(                 md_filepath, module_path, classes, functions             )             nav_items.append(str(md_rel_filepath))      create_nav_menu_yaml(nav_items) In\u00a0[\u00a0]: Copied! <pre>main()\n</pre> main()"}]}